{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNzNZcsyHAYT",
        "outputId": "dd7389e5-7dec-4803-d5e1-f64d04a02468"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "# import mailbox\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Navigate to your mail folder\n",
        "# emails_preprocessed = '/content/drive/MyDrive/mail_classification/Mail/emails_preprocessed.csv'"
      ]
    },
    {
<<<<<<< HEAD
=======
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- nenwwwerwer -->"
      ]
    },
    {
>>>>>>> ca3e75404bccb1ead8f5dbf4653b777983a7dc82
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FEiTrb_G3cB",
        "outputId": "a9b393b2-b6b5-4b44-dbdb-d15fd607645c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RECRUITMENT EMAIL DATASET ===\n",
            "Total emails: 1575\n",
            "Available columns: ['job_application', 'Application for Data Analyst – Amit Sharma\\r\\n\\r\\nHi HR Team,\\r\\n\\r\\nMy name is Amit Sharma, and I am currently working as a Data Analyst at Quantiva Systems. I have over 4 years of experience in data visualization, SQL-based analytics, and building dashboards using Power BI and Tableau.\\r\\n\\r\\nI came across your opening for a Data Analyst, and I believe my background aligns strongly with the role. I`ve handled several reporting automation initiatives and worked closely with cross-functional teams to deliver insights that improved operational decision-making.\\r\\n\\r\\nPlease find my attached résumé for your review. I would be happy to discuss how I can contribute.\\r\\n\\r\\nRegards,\\r\\nAmit Sharma\\r\\nEmail: amit.sharma92@gmail.com\\r\\n\\r\\n\\r\\nPhone: +91-98234-10020']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import re\n",
        "\n",
        "# Load your preprocessed data\n",
        "df = pd.read_csv(\"aws_training_data.csv\")\n",
        "\n",
        "print(\"=== RECRUITMENT EMAIL DATASET ===\")\n",
        "print(f\"Total emails: {len(df)}\")\n",
        "print(f\"Available columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hzG1udE9-GRR",
        "outputId": "e53b7a18-a95d-4bf9-d90b-6f0e1ca931d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_application</th>\n",
              "      <th>Application for Data Analyst – Amit Sharma\\r\\n\\r\\nHi HR Team,\\r\\n\\r\\nMy name is Amit Sharma, and I am currently working as a Data Analyst at Quantiva Systems. I have over 4 years of experience in data visualization, SQL-based analytics, and building dashboards using Power BI and Tableau.\\r\\n\\r\\nI came across your opening for a Data Analyst, and I believe my background aligns strongly with the role. I`ve handled several reporting automation initiatives and worked closely with cross-functional teams to deliver insights that improved operational decision-making.\\r\\n\\r\\nPlease find my attached résumé for your review. I would be happy to discuss how I can contribute.\\r\\n\\r\\nRegards,\\r\\nAmit Sharma\\r\\nEmail: amit.sharma92@gmail.com\\r\\n\\r\\n\\r\\nPhone: +91-98234-10020</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1575</td>\n",
              "      <td>1575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5</td>\n",
              "      <td>1526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>new_requisition</td>\n",
              "      <td>Subject: You’re Selected – UI Designer at Pixe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>516</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        job_application  \\\n",
              "count              1575   \n",
              "unique                5   \n",
              "top     new_requisition   \n",
              "freq                516   \n",
              "\n",
              "       Application for Data Analyst – Amit Sharma\\r\\n\\r\\nHi HR Team,\\r\\n\\r\\nMy name is Amit Sharma, and I am currently working as a Data Analyst at Quantiva Systems. I have over 4 years of experience in data visualization, SQL-based analytics, and building dashboards using Power BI and Tableau.\\r\\n\\r\\nI came across your opening for a Data Analyst, and I believe my background aligns strongly with the role. I`ve handled several reporting automation initiatives and worked closely with cross-functional teams to deliver insights that improved operational decision-making.\\r\\n\\r\\nPlease find my attached résumé for your review. I would be happy to discuss how I can contribute.\\r\\n\\r\\nRegards,\\r\\nAmit Sharma\\r\\nEmail: amit.sharma92@gmail.com\\r\\n\\r\\n\\r\\nPhone: +91-98234-10020  \n",
              "count                                                1575                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "unique                                               1526                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "top     Subject: You’re Selected – UI Designer at Pixe...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "freq                                                    4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zggPfXnG_3W-",
        "outputId": "c6dcb193-83e6-4dae-c071-b33d42bf8b67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\talentprism\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATASET LOADED ===\n",
            "Total emails: 1575\n",
            "Columns: ['job_application', 'Application for Data Analyst – Amit Sharma\\r\\n\\r\\nHi HR Team,\\r\\n\\r\\nMy name is Amit Sharma, and I am currently working as a Data Analyst at Quantiva Systems. I have over 4 years of experience in data visualization, SQL-based analytics, and building dashboards using Power BI and Tableau.\\r\\n\\r\\nI came across your opening for a Data Analyst, and I believe my background aligns strongly with the role. I`ve handled several reporting automation initiatives and worked closely with cross-functional teams to deliver insights that improved operational decision-making.\\r\\n\\r\\nPlease find my attached résumé for your review. I would be happy to discuss how I can contribute.\\r\\n\\r\\nRegards,\\r\\nAmit Sharma\\r\\nEmail: amit.sharma92@gmail.com\\r\\n\\r\\n\\r\\nPhone: +91-98234-10020']\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "['full_preprocessed']",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_21420\\3914865416.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m classifier, reply_templates\n\u001b[32m    372\u001b[39m \n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m __name__ == \u001b[33m\"__main__\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     classifier, templates = main()\n",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_21420\\3914865416.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    337\u001b[39m     print(f\"Total emails: {len(df)}\")\n\u001b[32m    338\u001b[39m     print(f\"Columns: {list(df.columns)}\")\n\u001b[32m    339\u001b[39m \n\u001b[32m    340\u001b[39m     \u001b[38;5;66;03m# Remove any rows with missing full_preprocessed text\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     df = df.dropna(subset=[\u001b[33m'full_preprocessed'\u001b[39m])\n\u001b[32m    342\u001b[39m     print(f\"After cleaning: {len(df)} emails\")\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# Train the classifier\u001b[39;00m\n",
            "\u001b[32me:\\talentprism\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6688\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6689\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6690\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6691\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6692\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6693\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6694\u001b[39m \n\u001b[32m   6695\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
            "\u001b[31mKeyError\u001b[39m: ['full_preprocessed']"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from collections import Counter\n",
        "\n",
        "class ATSEmailClassifier:\n",
        "    def __init__(self, max_features=8000, max_length=400):\n",
        "        self.max_features = max_features\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.model = None\n",
        "        self.num_classes = None\n",
        "\n",
        "    def prepare_data(self, texts, labels):\n",
        "        \"\"\"Prepare data for training\"\"\"\n",
        "        # Fit tokenizer\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "\n",
        "        # Convert texts to sequences\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
        "\n",
        "        # Encode labels\n",
        "        y = self.label_encoder.fit_transform(labels)\n",
        "        self.num_classes = len(np.unique(y))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Build the neural network model\"\"\"\n",
        "        model = Sequential([\n",
        "            Embedding(self.max_features, 128, input_length=self.max_length),\n",
        "            GlobalMaxPooling1D(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(self.num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "    def train(self, texts, labels, validation_split=0.2, epochs=25, batch_size=16):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        X, y = self.prepare_data(texts, labels)\n",
        "\n",
        "        # Build model\n",
        "        self.build_model()\n",
        "\n",
        "        # Compute class weights to handle imbalance\n",
        "        class_weights = compute_class_weight(\n",
        "            'balanced',\n",
        "            classes=np.unique(y),\n",
        "            y=y\n",
        "        )\n",
        "        class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "        print(f\"Training model with {self.num_classes} classes...\")\n",
        "        print(f\"Vocabulary size: {len(self.tokenizer.word_index)}\")\n",
        "        print(f\"Sample distribution: {Counter(y)}\")\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X, y,\n",
        "            validation_split=validation_split,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            class_weight=class_weight_dict,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict(self, texts):\n",
        "        \"\"\"Predict email categories\"\"\"\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
        "\n",
        "        predictions = self.model.predict(X)\n",
        "        predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "        return self.label_encoder.inverse_transform(predicted_classes)\n",
        "\n",
        "    def predict_proba(self, texts):\n",
        "        \"\"\"Get prediction probabilities\"\"\"\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
        "\n",
        "        predictions = self.model.predict(X)\n",
        "        return predictions\n",
        "\n",
        "    def evaluate(self, texts, labels):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
        "        y = self.label_encoder.transform(labels)\n",
        "\n",
        "        predictions = self.model.predict(X)\n",
        "        predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y, predicted_classes))\n",
        "\n",
        "        # Confusion Matrix\n",
        "        cm = confusion_matrix(y, predicted_classes)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.label_encoder.classes_,\n",
        "                   yticklabels=self.label_encoder.classes_)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return classification_report(y, predicted_classes, output_dict=True)\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the trained model\"\"\"\n",
        "        self.model.save(f\"{filepath}_model.h5\")\n",
        "        with open(f\"{filepath}_tokenizer.pkl\", 'wb') as f:\n",
        "            pickle.dump(self.tokenizer, f)\n",
        "        with open(f\"{filepath}_label_encoder.pkl\", 'wb') as f:\n",
        "            pickle.dump(self.label_encoder, f)\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load a trained model\"\"\"\n",
        "        self.model = tf.keras.models.load_model(f\"{filepath}_model.h5\")\n",
        "        with open(f\"{filepath}_tokenizer.pkl\", 'rb') as f:\n",
        "            self.tokenizer = pickle.load(f)\n",
        "        with open(f\"{filepath}_label_encoder.pkl\", 'rb') as f:\n",
        "            self.label_encoder = pickle.load(f)\n",
        "\n",
        "def categorize_emails(df):\n",
        "    \"\"\"Categorize emails based on content patterns with fallback\"\"\"\n",
        "    def classify_email(text):\n",
        "        if pd.isna(text):\n",
        "            return 'other'\n",
        "\n",
        "        text_lower = str(text).lower()\n",
        "\n",
        "        # Define keyword patterns for each category\n",
        "        patterns = {\n",
        "            'candidate_application': ['application', 'applied', 'resume', 'cv', 'portfolio', 'candidate profile'],\n",
        "            'candidate_availability': ['availability', 'schedule', 'time', 'when', 'flexible', 'available'],\n",
        "            'candidate_response': ['response', 'reply', 'answering', 'responding', 'acknowledging'],\n",
        "            'interview_scheduling': ['interview', 'meeting', 'schedule', 'set up', 'arrange', 'book', 'appointment'],\n",
        "            'interview_feedback': ['feedback', 'review', 'after', 'post', 'interview feedback'],\n",
        "            'interview_confirmation': ['confirm', 'confirmed', 'yes', 'ok', 'accepted', 'confirmed interview'],\n",
        "            'offer_sent': ['offer', 'salary', 'package', 'compensation', 'proposed', 'position offer'],\n",
        "            'offer_response': ['accept', 'accepted', 'decline', 'declined', 'negotiate', 'negotiation'],\n",
        "            'client_submission': ['submit', 'send', 'forward', 'present', 'candidate submission'],\n",
        "            'client_feedback': ['feedback', 'review', 'comment', 'client feedback', 'client response'],\n",
        "            'new_requisition': ['new', 'open', 'requirement', 'job requisition', 'position opening'],\n",
        "            'onboarding': ['onboarding', 'documents', 'start date', 'joining', 'orientation'],\n",
        "            'internal_coordination': ['internal', 'team', 'colleagues', 'coordinator', 'internal email'],\n",
        "            'system_notification': ['system', 'automated', 'notification', 'email notification'],\n",
        "            'general_inquiry': ['hello', 'hi', 'greeting', 'inquiry', 'question', 'help'],\n",
        "            'spam': ['spam', 'unsubscribe', 'advertisement', 'promotion', 'marketing'],\n",
        "        }\n",
        "\n",
        "        # Check each pattern\n",
        "        for category, keywords in patterns.items():\n",
        "            if any(keyword in text_lower for keyword in keywords):\n",
        "                return category\n",
        "\n",
        "        # Default to general inquiry if no specific pattern matches\n",
        "        return 'general_inquiry'\n",
        "\n",
        "    # Apply classification\n",
        "    df['category'] = df['full_preprocessed'].apply(classify_email)\n",
        "    return df\n",
        "\n",
        "def filter_rare_categories(df, min_samples=5):\n",
        "    \"\"\"Filter out categories with very few samples\"\"\"\n",
        "    category_counts = df['category'].value_counts()\n",
        "    valid_categories = category_counts[category_counts >= min_samples].index\n",
        "    filtered_df = df[df['category'].isin(valid_categories)].copy()\n",
        "\n",
        "    print(f\"Original categories: {len(category_counts)}\")\n",
        "    print(f\"Valid categories (≥{min_samples} samples): {len(valid_categories)}\")\n",
        "    print(f\"Samples kept: {len(filtered_df)} out of {len(df)}\")\n",
        "    print(\"\\nCategory distribution after filtering:\")\n",
        "    print(filtered_df['category'].value_counts())\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "def train_classifier(df):\n",
        "    \"\"\"Train the ATS email classifier\"\"\"\n",
        "    # Categorize emails\n",
        "    df = categorize_emails(df)\n",
        "\n",
        "    # Filter out rare categories\n",
        "    df_filtered = filter_rare_categories(df, min_samples=3)\n",
        "\n",
        "    if len(df_filtered) < 10:  # Need minimum samples for training\n",
        "        print(\"Not enough data after filtering. Using simplified approach...\")\n",
        "        # Fallback: group rare categories\n",
        "        category_counts = df['category'].value_counts()\n",
        "        threshold = 5\n",
        "        df['category'] = df['category'].apply(\n",
        "            lambda x: 'other' if category_counts[x] < threshold else x\n",
        "        )\n",
        "        df_filtered = df[df['category'] != 'other']  # Remove 'other' for training\n",
        "\n",
        "        if len(df_filtered) < 10:\n",
        "            df_filtered = df  # Use all data if still too small\n",
        "\n",
        "    # Prepare data\n",
        "    texts = df_filtered['full_preprocessed'].fillna('').tolist()\n",
        "    labels = df_filtered['category'].tolist()\n",
        "\n",
        "    # Check if we have enough samples for each class\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    min_count = min(counts)\n",
        "\n",
        "    if min_count < 2:\n",
        "        print(\"Some classes have only 1 sample. Using stratified split with validation split = 0.1\")\n",
        "        validation_split = 0.1\n",
        "    else:\n",
        "        validation_split = 0.2 if len(texts) > 50 else 0.1\n",
        "\n",
        "    # Split data ensuring minimum samples per class\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42,\n",
        "            stratify=labels if min_count >= 2 else None\n",
        "        )\n",
        "    except:\n",
        "        # Fallback if stratification fails\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "    # Initialize and train classifier\n",
        "    classifier = ATSEmailClassifier(max_features=8000, max_length=400)\n",
        "\n",
        "    print(f\"\\n=== TRAINING ATS EMAIL CLASSIFIER ===\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Test samples: {len(X_test)}\")\n",
        "    print(f\"Unique categories: {len(set(y_train))}\")\n",
        "\n",
        "    history = classifier.train(X_train, y_train, epochs=30, batch_size=16)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(f\"\\n=== EVALUATION RESULTS ===\")\n",
        "    classifier.evaluate(X_test, y_test)\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return classifier\n",
        "\n",
        "def create_reply_templates():\n",
        "    \"\"\"Create automated reply templates based on categories\"\"\"\n",
        "    reply_templates = {\n",
        "        'candidate_application': \"Thank you for your application. We have received your resume and will review it. We'll get back to you within 3-5 business days.\",\n",
        "        'candidate_availability': \"Thank you for providing your availability. We'll schedule your interview soon and send you the details.\",\n",
        "        'candidate_response': \"Thank you for your response. We appreciate your interest in this position.\",\n",
        "        'interview_scheduling': \"We'd like to schedule your interview. Please confirm your availability for the proposed time.\",\n",
        "        'interview_feedback': \"Thank you for attending the interview. We'll provide feedback soon.\",\n",
        "        'interview_confirmation': \"Thank you for confirming your interview. We look forward to meeting you.\",\n",
        "        'offer_sent': \"Congratulations! We'd like to offer you the position. Please review the offer details and let us know your decision.\",\n",
        "        'offer_response': \"Thank you for your response regarding the offer. We'll proceed accordingly.\",\n",
        "        'client_submission': \"We have submitted the candidate profile to the client. We'll update you on their feedback.\",\n",
        "        'client_feedback': \"Thank you for the client feedback. We'll take it into consideration.\",\n",
        "        'new_requisition': \"Thank you for the new job requisition. We'll start sourcing suitable candidates immediately.\",\n",
        "        'onboarding': \"Please complete the onboarding documents attached. Let us know if you need any assistance.\",\n",
        "        'internal_coordination': \"Internal coordination email processed successfully.\",\n",
        "        'system_notification': \"System notification processed.\",\n",
        "        'general_inquiry': \"Thank you for your inquiry. We'll address your query and get back to you soon.\",\n",
        "        'spam': \"This email has been marked as spam and will be handled accordingly.\",\n",
        "        'other': \"Thank you for your message. We'll review it and respond accordingly.\"\n",
        "    }\n",
        "    return reply_templates\n",
        "\n",
        "def generate_automated_reply(classifier, email_text, reply_templates):\n",
        "    \"\"\"Generate automated reply based on email classification\"\"\"\n",
        "    try:\n",
        "        predicted_category = classifier.predict([email_text])[0]\n",
        "        template = reply_templates.get(predicted_category, \"Thank you for your message.\")\n",
        "\n",
        "        print(f\"Email Category: {predicted_category}\")\n",
        "        print(f\"Automated Reply: {template}\")\n",
        "\n",
        "        return template\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating reply: {e}\")\n",
        "        return \"Thank you for your message. We'll review it and respond accordingly.\"\n",
        "\n",
        "# Load and train with your data\n",
        "def main():\n",
        "    # Load your data\n",
        "    df = pd.read_csv('aws_training_data.csv')\n",
        "\n",
        "    print(\"=== DATASET LOADED ===\")\n",
        "    print(f\"Total emails: {len(df)}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "    # Remove any rows with missing full_preprocessed text\n",
        "    df = df.dropna(subset=['full_preprocessed'])\n",
        "    print(f\"After cleaning: {len(df)} emails\")\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier = train_classifier(df)\n",
        "\n",
        "    # Save the model\n",
        "    classifier.save_model(\"ats_email_classifier\")\n",
        "\n",
        "    # Create reply templates\n",
        "    reply_templates = create_reply_templates()\n",
        "\n",
        "    # Test with sample emails\n",
        "    test_emails = [\n",
        "        \"I have attached my resume for the software engineer position. Please let me know if you need any additional information.\",\n",
        "        \"I'm available for an interview next week on Tuesday or Wednesday. Please let me know what works for you.\",\n",
        "        \"Thank you for the interview opportunity. I would like to accept your offer for the position.\",\n",
        "        \"We have reviewed the candidate's profile and would like to schedule an interview next week.\",\n",
        "        \"Please find the attached onboarding documents for the new hire.\",\n",
        "        \"I am applying for the offer offer buy this car get it for free. Attached is my resume.\"\n",
        "\n",
        "    ]\n",
        "\n",
        "    print(\"\\n=== TEST PREDICTIONS AND AUTOMATED REPLIES ===\")\n",
        "    for i, email in enumerate(test_emails, 1):\n",
        "        print(f\"\\n--- Test Email {i} ---\")\n",
        "        print(f\"Email: {email[:100]}...\")\n",
        "        reply = generate_automated_reply(classifier, email, reply_templates)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    return classifier, reply_templates\n",
        "    \n",
        "# Run the training\n",
        "if __name__ == \"__main__\":\n",
        "    classifier, templates = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'classifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m email \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am applying for the offer offer buy this car get it for free. Attached is my resume.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict([email])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmail:\u001b[39m\u001b[38;5;124m\"\u001b[39m, email)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Category:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
          ]
        }
      ],
      "source": [
        "email = \"I am applying for the offer offer buy this car get it for free. Attached is my resume.\"\n",
        "\n",
        "prediction = classifier.predict([email])[0]\n",
        "\n",
        "print(\"Email:\", email)\n",
        "print(\"Predicted Category:\", prediction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'classifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_email \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am applying for the offer offer buy this car get it for free. Attached is my resume.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict([test_email])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmail:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_email)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Category:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
          ]
        }
      ],
      "source": [
        "test_email = \"I am applying for the offer offer buy this car get it for free. Attached is my resume.\"\n",
        "\n",
        "prediction = classifier.predict([test_email])[0]\n",
        "\n",
        "print(\"Email:\", test_email)\n",
        "print(\"Predicted Category:\", prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8HNQ7FyAHcR",
        "outputId": "a27b2e29-f621-42e5-fa1a-822eb37855c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'ats_email_classifier_tokenizer.pkl', 'ats_email_classifier_model.h5', 'ats_email_classifier_label_encoder.pkl', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHoHaAel8kgy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
