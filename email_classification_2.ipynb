{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5).head()\n",
    "df['text'][1762]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea076b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data cleaning \n",
    "# 2. Exploratory Data Analysis \n",
    "# 3. text preprocessing\n",
    "# 4. Model building\n",
    "# 5. Model evaluation\n",
    "# 6. Improvement and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169a8ed",
   "metadata": {},
   "source": [
    "## 1. Data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15b755",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7035bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImprovedATSEmailClassifier:\n",
    "#     def __init__(self, max_features=10000, max_length=500):\n",
    "#         self.max_features = max_features\n",
    "#         self.max_length = max_length\n",
    "#         self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.model = None\n",
    "#         self.num_classes = None\n",
    "\n",
    "#     def preprocess_text(self, text):\n",
    "#         \"\"\"Clean text: lowercase, remove punctuation, stop words.\"\"\"\n",
    "#         text = text.lower()\n",
    "#         text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "#         text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "#         return text\n",
    "\n",
    "#     def prepare_data(self, texts, labels):\n",
    "#         \"\"\"Prepare data with preprocessing.\"\"\"\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         # self.tokenizer.fit_on_texts(texts)\n",
    "#         if is_training:\n",
    "#             self.tokenizer.fit_on_texts(texts)\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         y = self.label_encoder.fit_transform(labels)\n",
    "#         self.num_classes = len(np.unique(y))\n",
    "#         return X, y\n",
    "\n",
    "#     def build_model(self):\n",
    "#         \"\"\"Improved model: Bidirectional LSTM for better sequence handling.\"\"\"\n",
    "#         model = Sequential([\n",
    "#             Embedding(self.max_features, 128, input_length=self.max_length),\n",
    "#             Bidirectional(LSTM(64, return_sequences=True)),  # Better for context\n",
    "#             GlobalMaxPooling1D(),\n",
    "#             Dense(128, activation='relu'),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(64, activation='relu'),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(self.num_classes, activation='softmax')\n",
    "#         ])\n",
    "#         model.compile(\n",
    "#             optimizer='adam',\n",
    "#             loss='sparse_categorical_crossentropy',\n",
    "#             metrics=['accuracy']\n",
    "#         )\n",
    "#         self.model = model\n",
    "#         return model\n",
    "\n",
    "#     def train(self, texts, labels, validation_split=0.2, epochs=10, batch_size=32):\n",
    "#         X, y = self.prepare_data(texts, labels)\n",
    "#         self.build_model()\n",
    "        \n",
    "#         # Class weights for imbalance\n",
    "#         class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "#         class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "#         # Early stopping to prevent overfitting\n",
    "#         early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "#         history = self.model.fit(\n",
    "#             X, y,\n",
    "#             validation_split=validation_split,\n",
    "#             epochs=10,\n",
    "#             batch_size=batch_size,\n",
    "#             class_weight=class_weight_dict,\n",
    "#             callbacks=[early_stop],\n",
    "#             verbose=1\n",
    "#         )\n",
    "#         return history\n",
    "\n",
    "#     def predict(self, texts):\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "#         return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "#     def evaluate(self, texts, labels):\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         y = self.label_encoder.transform(labels)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "#         print(\"Classification Report:\")\n",
    "#         print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "        \n",
    "#         cm = confusion_matrix(y, predicted_classes)\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#                    xticklabels=self.label_encoder.classes_,\n",
    "#                    yticklabels=self.label_encoder.classes_)\n",
    "#         plt.title('Confusion Matrix')\n",
    "#         plt.ylabel('Actual')\n",
    "#         plt.xlabel('Predicted')\n",
    "#         plt.xticks(rotation=45)\n",
    "#         plt.yticks(rotation=0)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf225f",
   "metadata": {},
   "source": [
    "# LSTM MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294301d",
   "metadata": {},
   "source": [
    "## This is the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, Bidirectional\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from tensorflow.keras.layers import Attention\n",
    "\n",
    "\n",
    "# # Download stopwords if needed\n",
    "# # nltk.download('stopwords')\n",
    "# # stop_words = set(stopwords.words('english'))\n",
    "# try:\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "# except LookupError:\n",
    "#     nltk.download('stopwords')\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# class ImprovedATSEmailClassifier:\n",
    "#     def __init__(self, max_features=20000, max_length=500):\n",
    "#         self.max_features = max_features\n",
    "#         self.max_length = max_length\n",
    "#         self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.model = None\n",
    "#         self.num_classes = None\n",
    "\n",
    "#     def preprocess_text(self, text):\n",
    "#         # Convert to string and cap length (PROTECTION STEP)\n",
    "#         text = str(text)[:5000]\n",
    "\n",
    "#         # Normalize\n",
    "#         text = text.lower()\n",
    "\n",
    "#         # Keep meaningful characters (emails, %, numbers)\n",
    "#         text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "\n",
    "#         # Optional: keep stopwords for LSTM context (recommended)\n",
    "#         # If you keep stopword removal, do it AFTER truncation\n",
    "#         text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "#         return text\n",
    "\n",
    "\n",
    "#     def prepare_data(self, texts, labels=None, is_training=True):\n",
    "#         \"\"\"Prepare data with preprocessing. Added is_training logic.\"\"\"\n",
    "#         processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "#         # FIX: Only fit the dictionary during the training phase\n",
    "#         if is_training:\n",
    "#             self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "#         sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "#         if labels is not None:\n",
    "#             if is_training:\n",
    "#                 y = self.label_encoder.fit_transform(labels)\n",
    "#                 self.num_classes = len(np.unique(y))\n",
    "#             else:\n",
    "#                 unknown_labels = set(labels) - set(self.label_encoder.classes_)\n",
    "#                 if unknown_labels:\n",
    "#                     raise ValueError(\n",
    "#                         f\"Unknown label(s) detected: {unknown_labels}. \"\n",
    "#                         \"Model was not trained on these classes.\"\n",
    "#                 )\n",
    "#                 y = self.label_encoder.transform(labels)\n",
    "#             return X, y\n",
    "#         return X\n",
    "\n",
    "#     def build_model(self):\n",
    "#         # Input layer\n",
    "#         inputs = Input(shape=(self.max_length,))\n",
    "\n",
    "#         # Embedding\n",
    "#         x = Embedding(\n",
    "#             input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "#             output_dim=128\n",
    "#         )(inputs)\n",
    "\n",
    "#         # BiLSTM\n",
    "#         x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "#         # Self-attention\n",
    "#         x = Attention()([x, x])\n",
    "\n",
    "#         # Reduce sequence dimension\n",
    "#         x = tf.reduce_mean(x, axis=1)\n",
    "\n",
    "#         # Dense layers\n",
    "#         x = Dense(128, activation='relu')(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "#         x = Dense(64, activation='relu')(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "\n",
    "#         # Output\n",
    "#         outputs = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "#         # Build model\n",
    "#         model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#         model.compile(\n",
    "#             optimizer='adam',\n",
    "#             loss='sparse_categorical_crossentropy',\n",
    "#             metrics=['accuracy']\n",
    "#         )\n",
    "\n",
    "#         self.model = model\n",
    "#         return model\n",
    "    \n",
    "#     def train(self, X_train, y_train,X_val,epochs=10,batch_size=32):\n",
    "#          # Prepare training data\n",
    "#         X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        \n",
    "#         # Prepare validation data (NO fitting here)\n",
    "#         X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "#         # 2. Debug label mapping\n",
    "#         mapping = dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))\n",
    "#         print(f\"\\n[DEBUG] Label Mapping is: {mapping}\")\n",
    "        \n",
    "#         # 3. Build and compile the model\n",
    "#         self.build_model()\n",
    "        \n",
    "#         # 4. Calculate class weights for balance\n",
    "#         class_weights = compute_class_weight(\n",
    "#             class_weight='balanced',\n",
    "#             classes=np.unique(y_tr),\n",
    "#             y=y_tr\n",
    "#         )\n",
    "#         class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "#         # 5. Setup Early Stopping to prevent overfitting\n",
    "#         early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss', \n",
    "#             patience=3, \n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "        \n",
    "#          # Train\n",
    "#         history = self.model.fit(\n",
    "#             X_tr,\n",
    "#             y_tr,\n",
    "#             validation_data=(X_v, y_v),\n",
    "#             epochs=epochs,\n",
    "#             batch_size=batch_size,\n",
    "#             class_weight=class_weight_dict,\n",
    "#             callbacks=[early_stop],\n",
    "#             verbose=1\n",
    "#         )\n",
    "#         return history\n",
    "\n",
    "#     def predict(self, texts):\n",
    "#         # Pass is_training=False to keep the tokenizer dictionary locked\n",
    "#         X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "#         return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "#     # def evaluate(self, texts, labels):\n",
    "#     #     # Pass is_training=False for evaluation\n",
    "#     #     X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "#     #     predictions = self.model.predict(X)\n",
    "#     #     predicted_classes = np.argmax(predictions, axis=1)\n",
    "#     #     print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "    \n",
    "#     # def predict_probabilities(self, texts):\n",
    "#     #     X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#     #     preds = self.model.predict(X)\n",
    "#     #     for i, p in enumerate(preds):\n",
    "#     #         print(f\"Text: {texts[i][:50]}...\")\n",
    "#     #         for j, class_name in enumerate(self.label_encoder.classes_):\n",
    "#     #             print(f\" - {class_name}: {p[j]*100:.2f}%\")\n",
    "\n",
    "#     def evaluate(self, texts, labels):\n",
    "#         \"\"\"Prints classification report and plots a Confusion Matrix heatmap.\"\"\"\n",
    "#         X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "#         # 1. Classification Report\n",
    "#         print(\"\\n\" + \"=\"*30)\n",
    "#         print(\"CLASSIFICATION REPORT\")\n",
    "#         print(\"=\"*30)\n",
    "#         print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_, digits =4))\n",
    "        \n",
    "#         # 2. Confusion Matrix\n",
    "#         cm = confusion_matrix(y, predicted_classes)\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "#                     xticklabels=self.label_encoder.classes_, \n",
    "#                     yticklabels=self.label_encoder.classes_)\n",
    "#         plt.title('Confusion Matrix: Actual vs. Predicted')\n",
    "#         plt.ylabel('Actual Category')\n",
    "#         plt.xlabel('Predicted Category')\n",
    "#         plt.show()\n",
    "\n",
    "#     def predict_probabilities(self, texts):\n",
    "#         \"\"\"Shows exactly how confident the model is for every category.\"\"\"\n",
    "#         X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#         preds = self.model.predict(X)\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*30)\n",
    "#         print(\"CONFIDENCE SCORES\")\n",
    "#         print(\"=\"*30)\n",
    "#         for i, p in enumerate(preds):\n",
    "#             print(f\"Text snippet: '{texts[i][:60]}...'\")\n",
    "#             # Sort by highest confidence\n",
    "#             sorted_indices = np.argsort(p)[::-1]\n",
    "#             for idx in sorted_indices:\n",
    "#                 class_name = self.label_encoder.classes_[idx]\n",
    "#                 confidence = p[idx] * 100\n",
    "#                 print(f\"  --> {class_name}: {confidence:.2f}%\")\n",
    "#             print(\"-\" * 20)\n",
    "\n",
    "# # Load data from CSV (assuming columns are 'category' and the email text column; adjust if needed)\n",
    "# # df = pd.read_csv('final_training_data.csv')\n",
    "# # Load data\n",
    "# df = pd.read_csv('final_training_data1.csv')\n",
    "# df.columns = ['label', 'text']\n",
    "\n",
    "# # 1Ô∏è‚É£ Drop NaNs FIRST\n",
    "# df = df.dropna(subset=['text', 'label'])\n",
    "\n",
    "# # 2Ô∏è‚É£ Drop duplicate emails\n",
    "# df = df.drop_duplicates(subset=['text'])\n",
    "\n",
    "# # 3Ô∏è‚É£ Shuffle dataset (important before capping)\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # 4Ô∏è‚É£ Cap samples per category (balanced dataset)\n",
    "# MAX_PER_CLASS = 450\n",
    "# df = df.groupby('label').head(MAX_PER_CLASS)\n",
    "\n",
    "# # 5Ô∏è‚É£ Verify distribution\n",
    "# print(\"Final label distribution:\")\n",
    "# print(df['label'].value_counts())\n",
    "\n",
    "# # df = df.dropna(subset=['text'])\n",
    "# texts = df['text'].tolist()\n",
    "# labels = df['label'].tolist()\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# # Train model\n",
    "# classifier = ImprovedATSEmailClassifier()\n",
    "# history = classifier.train(X_train, y_train, epochs=10)\n",
    "\n",
    "# # Evaluate\n",
    "# classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# # Plot training history\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Model Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Test prediction\n",
    "# # test_email = \"I am applying for the data analyst position. Attached is my resume.\"\n",
    "# # print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")\n",
    "# # test_email = \"I am applying for the offer offer buy this car get a gift free. Attached is my resume.\"\n",
    "# # print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") \n",
    "\n",
    "# # ... (Previous training code) ...\n",
    "\n",
    "# # 1. Run evaluation (This will now show the Confusion Matrix plot)\n",
    "# # classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# # 2. Test specific emails with CONFIDENCE NUMBERS\n",
    "# test_emails = [\n",
    "#     \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "#     \"I am applying for the offer offer buy this car get a gift free. Attached is my resume.\"\n",
    "# ]\n",
    "\n",
    "# classifier.predict_probabilities(test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ff17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Embedding, LSTM,\n",
    "    Bidirectional, Attention,\n",
    "    GlobalAveragePooling1D, Input\n",
    ")\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a12e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=8000, max_length=500):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    # def preprocess_text(self, text):\n",
    "    #     text = str(text)[:5000]\n",
    "    #     text = text.lower()\n",
    "    #     text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "    #     text = ' '.join(w for w in text.split() if w not in stop_words)\n",
    "    #     return text\n",
    "    def preprocess_text(self, text):\n",
    "        text = str(text)[:5000]\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        texts = [self.preprocess_text(t) for t in texts]\n",
    "\n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "\n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                unknown = set(labels) - set(self.label_encoder.classes_)\n",
    "                if unknown:\n",
    "                    raise ValueError(f\"Unknown labels detected: {unknown}\")\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=(self.max_length,))\n",
    "        x = Embedding(\n",
    "            input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "            output_dim=128\n",
    "        )(inputs)\n",
    "\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        # x = Attention()([x, x])\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        # x = Dense(64, activation='relu')(x)\n",
    "        # x = Dropout(0.3)(x)\n",
    "\n",
    "        outputs = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        self.model = Model(inputs, outputs)\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=15, batch_size=32):\n",
    "        X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_tr),\n",
    "            y=y_tr\n",
    "        )\n",
    "        class_weight = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            \n",
    "            patience=4,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        return self.model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_v, y_v),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        preds = np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "        print(classification_report(\n",
    "            y, preds,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            digits=4\n",
    "        ))\n",
    "\n",
    "        cm = confusion_matrix(y, preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.show()\n",
    "\n",
    "    def predict_probabilities(self, texts):\n",
    "        X = self.prepare_data(texts, is_training=False)\n",
    "        preds = self.model.predict(X)\n",
    "\n",
    "        for i, p in enumerate(preds):\n",
    "            print(f\"\\nText: {texts[i][:60]}...\")\n",
    "            for idx in np.argsort(p)[::-1]:\n",
    "                print(f\"{self.label_encoder.classes_[idx]}: {p[idx]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data1.csv')\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "df = df.dropna(subset=['label', 'text'])\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "df = df.groupby('label').head(450)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "# )\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    "# )\n",
    "\n",
    "# classifier = ImprovedATSEmailClassifier()\n",
    "# history = classifier.train(X_train, y_train, X_val, y_val, epochs=10)\n",
    "# classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "classifier = ImprovedATSEmailClassifier()\n",
    "history = classifier.train(X_train, y_train, X_val, y_val, epochs=15)\n",
    "classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b943fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SAVE MODEL ARTIFACTS (RUN AFTER TRAINING) =====\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "MODEL_DIR = \"model2\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# 1Ô∏è‚É£ Save trained Keras model\n",
    "classifier.model.save(os.path.join(MODEL_DIR, \"ats_email_model.keras\"))\n",
    "\n",
    "# 2Ô∏è‚É£ Save tokenizer\n",
    "with open(os.path.join(MODEL_DIR, \"tokenizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(classifier.tokenizer, f)\n",
    "\n",
    "# 3Ô∏è‚É£ Save label encoder\n",
    "with open(os.path.join(MODEL_DIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(classifier.label_encoder, f)\n",
    "\n",
    "# 4Ô∏è‚É£ Save config (important for inference)\n",
    "config = {\n",
    "    \"max_features\": classifier.max_features,\n",
    "    \"max_length\": classifier.max_length\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Model, tokenizer, label encoder, and config saved in 'model/' folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753ddede",
   "metadata": {},
   "source": [
    "# This the downloaded data for spam as emails,csv from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ===== LOAD CSV =====\n",
    "csv_path = \"emails.csv\"   # change if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns in your CSV\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "true_labels = df[\"spam\"].astype(int).tolist()   # 1 = spam, 0 = not spam\n",
    "\n",
    "# ===== PREPARE DATA =====\n",
    "X_test = classifier.prepare_data(texts, is_training=False)\n",
    "\n",
    "# ===== PREDICT =====\n",
    "y_pred_probs = classifier.model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# ===== MAP MODEL OUTPUT TO BINARY =====\n",
    "# Adjust this if your label_encoder mapping is different\n",
    "label_map = {\n",
    "    \"spam\": 1,\n",
    "    \"not_spam\": 0,\n",
    "    \"job_application\": 0,\n",
    "    \"interview_scheduling\": 0,\n",
    "    \"candidate_selection\": 0,\n",
    "    \"new_requisition\": 0\n",
    "}\n",
    "\n",
    "y_pred_binary = [\n",
    "    label_map[classifier.label_encoder.classes_[i]] for i in y_pred\n",
    "]\n",
    "\n",
    "# ===== METRICS =====\n",
    "total = len(true_labels)\n",
    "correct = sum(t == p for t, p in zip(true_labels, y_pred_binary))\n",
    "wrong = total - correct\n",
    "\n",
    "correct_pct = (correct / total) * 100\n",
    "wrong_pct = (wrong / total) * 100\n",
    "accuracy = accuracy_score(true_labels, y_pred_binary)\n",
    "\n",
    "# ===== OUTPUT =====\n",
    "print(\"üìä MODEL TEST RESULTS\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Total Samples        : {total}\")\n",
    "print(f\"Correct Predictions  : {correct} ({correct_pct:.2f}%)\")\n",
    "print(f\"Wrong Predictions    : {wrong} ({wrong_pct:.2f}%)\")\n",
    "print(f\"Overall Accuracy     : {accuracy:.4f}\")\n",
    "\n",
    "# ===== CLASSIFICATION REPORT =====\n",
    "print(\"\\nüìÑ Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    y_pred_binary,\n",
    "    target_names=[\"not_spam\", \"spam\"],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# ===== CONFUSION MATRIX =====\n",
    "cm = confusion_matrix(true_labels, y_pred_binary)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"not_spam\", \"spam\"],\n",
    "    yticklabels=[\"not_spam\", \"spam\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Spam Classification Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7e4cb",
   "metadata": {},
   "source": [
    "# changes Made by Ayush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57184c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Embedding, LSTM,\n",
    "    Bidirectional, GlobalAveragePooling1D, Input, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=8000, max_length=500, embedding_dim=128):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    # More comprehensive preprocessing\n",
    "    def preprocess_text(self, text):\n",
    "        text = str(text)[:5000] # Limit length to prevent memory issues\n",
    "        text = text.lower()\n",
    "        # Expand contractions (basic example, can be improved)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"n't\", \" not\", text)\n",
    "        text = re.sub(r\"'re\", \" are\", text)\n",
    "        text = re.sub(r\"'ve\", \" have\", text)\n",
    "        text = re.sub(r\"'ll\", \" will\", text)\n",
    "        text = re.sub(r\"'d\", \" would\", text)\n",
    "        text = re.sub(r\"'m\", \" am\", text)\n",
    "        # Remove special characters, keep essential ones like @, ., +, - for emails/URLs\n",
    "        text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove leading/trailing spaces\n",
    "        return text.strip()\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        texts = [self.preprocess_text(t) for t in texts]\n",
    "\n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "\n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "                print(f\"Number of classes: {self.num_classes}, Classes: {self.label_encoder.classes_}\")\n",
    "            else:\n",
    "                # Handle unknown labels during prediction if necessary\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer\n",
    "        inputs = Input(shape=(self.max_length,))\n",
    "\n",
    "        # Embedding layer\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "            output_dim=self.embedding_dim,\n",
    "            input_length=self.max_length,\n",
    "            # Add regularization to embedding layer\n",
    "            embeddings_regularizer=l2(1e-4)\n",
    "        )(inputs)\n",
    "\n",
    "        # Dropout on embeddings to prevent overfitting to specific word vectors\n",
    "        embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "        # BiLSTM layer with return sequences for potential subsequent pooling/attention\n",
    "        lstm_out = Bidirectional(\n",
    "            LSTM(64, return_sequences=True, recurrent_dropout=0.2, recurrent_regularizer=l2(1e-4))\n",
    "        )(embedding_layer)\n",
    "\n",
    "        # Global Average Pooling (GAP) - Good for capturing overall meaning\n",
    "        gap = GlobalAveragePooling1D()(lstm_out)\n",
    "\n",
    "        # Dense layers with regularization and dropout\n",
    "        dense1 = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(gap)\n",
    "        dropout1 = Dropout(0.5)(dense1) # Higher dropout for dense layer\n",
    "\n",
    "        dense2 = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(dropout1)\n",
    "        dropout2 = Dropout(0.3)(dense2)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = Dense(self.num_classes, activation='softmax')(dropout2)\n",
    "\n",
    "        self.model = Model(inputs, outputs)\n",
    "        # Using a lower learning rate initially\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=32): # Increased epochs\n",
    "        X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        # Compute class weights (still useful)\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_tr),\n",
    "            y=y_tr\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        print(f\"Class Weights: {class_weight_dict}\")\n",
    "\n",
    "        # Callbacks\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=6, # Increased patience\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5, # Reduce LR by half\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        history = self.model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_v, y_v),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop, reduce_lr], # Added ReduceLROnPlateau\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        preds = np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "        print(\"\\n--- Detailed Classification Report ---\")\n",
    "        print(classification_report(\n",
    "            y, preds,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            digits=4\n",
    "        ))\n",
    "\n",
    "        print(\"\\n--- Per-Class Precision, Recall, F1-Score ---\")\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y, preds, average=None, labels=np.unique(y))\n",
    "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
    "            print(f\"{class_name}: P={precision[i]:.4f}, R={recall[i]:.4f}, F1={f1[i]:.4f}, Support={support[i]}\")\n",
    "\n",
    "        cm = confusion_matrix(y, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "\n",
    "    def predict_probabilities(self, texts):\n",
    "        X = self.prepare_data(texts, is_training=False)\n",
    "        preds = self.model.predict(X)\n",
    "\n",
    "        for i, p in enumerate(preds):\n",
    "            print(f\"\\n--- Text {i+1}: {texts[i][:100]}... ---\") # Show more of the text\n",
    "            sorted_indices = np.argsort(p)[::-1]\n",
    "            for idx in sorted_indices[:2]: # Show top 2 predictions\n",
    "                class_name = self.label_encoder.classes_[idx]\n",
    "                prob = p[idx]\n",
    "                print(f\"  {class_name}: {prob*100:.2f}%\")\n",
    "            # Add a threshold check if needed\n",
    "            max_prob = np.max(p)\n",
    "            if max_prob < 0.7: # Example threshold\n",
    "                print(f\"  [Low Confidence: Max Prob = {max_prob*100:.2f}%]\")\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "df = pd.read_csv('final_training_data1.csv')\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "df = df.dropna(subset=['label', 'text'])\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# --- Investigate Class Distribution BEFORE balancing ---\n",
    "print(\"--- Original Class Distribution ---\")\n",
    "original_counts = df['label'].value_counts()\n",
    "print(original_counts)\n",
    "print(f\"Total samples before balancing: {len(df)}\")\n",
    "\n",
    "# Balance the dataset by taking up to 450 samples per class (or less if fewer exist)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(min(len(x), 450), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Balanced Class Distribution ---\")\n",
    "balanced_counts = df_balanced['label'].value_counts()\n",
    "print(balanced_counts)\n",
    "print(f\"Total samples after balancing: {len(df_balanced)}\")\n",
    "\n",
    "texts = df_balanced['text'].tolist()\n",
    "labels = df_balanced['label'].tolist()\n",
    "\n",
    "# --- Split Data ---\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    texts, labels, test_size=0.3, stratify=labels, random_state=42 # Increased test size slightly\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42 # ~0.2 of total\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# --- Initialize and Train Model ---\n",
    "classifier = ImprovedATSEmailClassifier(max_features=8000, max_length=500, embedding_dim=128)\n",
    "history = classifier.train(X_train, y_train, X_val, y_val, epochs=20, batch_size=32)\n",
    "\n",
    "# --- Evaluate on Test Set ---\n",
    "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
    "classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# --- Plot Training History ---\n",
    "if history:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Example Prediction on New Data ---\n",
    "# Replace these with your truly new data\n",
    "new_texts = [\n",
    "    \"Dear Hiring Manager, I am writing to apply for the Data Scientist position...\",\n",
    "    \"Subject: New Role: Content Writer (Finance)...\",\n",
    "    \"URGENT!! You have been selected to receive a Free Trip!...\",\n",
    "    # Add more examples from your new data\n",
    "]\n",
    "\n",
    "print(\"\\n--- Predictions on New Texts ---\")\n",
    "classifier.predict_probabilities(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "spam_emails= pd.read_csv('emails.csv')\n",
    "print(spam_emails.describe())\n",
    "spam_emails.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7197068",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = [\n",
    "    \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "    \"Buy now! Free gift offer limited time\"\n",
    "]\n",
    "classifier.predict_probabilities(test_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = \" unsubscribe offer offer buy this car get a gift free.\"\n",
    "print(f\"Predicted Category: {classifier.predict_probabilities(test_emails)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" i want to  apply offer offer buy this car get a gift free.\"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179125d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to your ImprovedATSEmailClassifier class\n",
    "def predict_probabilities(self, texts):\n",
    "    X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "    preds = self.model.predict(X)\n",
    "    for i, p in enumerate(preds):\n",
    "        print(f\"Text: {texts[i][:50]}...\")\n",
    "        for j, class_name in enumerate(self.label_encoder.classes_):\n",
    "            print(f\" - {class_name}: {p[j]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19623f2c",
   "metadata": {},
   "source": [
    "# checking the working of model work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c912b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# A list of \"tricky\" emails covering all 5 labels\n",
    "test_data = [\n",
    "    # Testing SPAM (with job keywords)\n",
    "    \"I want to apply offer offer buy this car get a gift free.\",\n",
    "    \"URGENT: Your job application requires a $500 processing fee. Click here to win!\",\n",
    "    \n",
    "    # Testing JOB_APPLICATION (with unusual phrasing)\n",
    "    \"Please find my resume attached for the open position, I am very interested.\",\n",
    "    \"Submission of candidate profile for the engineering role.\",\n",
    "    \n",
    "    # Testing CANDIDATE_SELECTION (Internal HR talk)\n",
    "    \"The hiring committee has finalized the selection for the Senior Dev role.\",\n",
    "    \"We have chosen a candidate from the final shortlist, please inform the team.\",\n",
    "    \n",
    "    # Testing INTERVIEW_SCHEDULING (Time/Date focus)\n",
    "    \"Are you available for a Zoom call this Thursday at 10 AM?\",\n",
    "    \"Confirming the technical interview for next Monday.\",\n",
    "    \n",
    "    # Testing NEW_REQUISITION (Managerial/Internal)\n",
    "    \"Need approval for a new requisition for the Sales Department.\",\n",
    "    \"Budget approved for a new headcount: please open a requisition for a Designer.\"\n",
    "]\n",
    "\n",
    "# Randomize the order\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(\"--- Multi-Label Stress Test ---\")\n",
    "for email in test_data:\n",
    "    prediction = classifier.predict([email])[0]\n",
    "    print(f\"Test Text: \\\"{email[:60]}...\\\"\")\n",
    "    print(f\"Predicted Category: {prediction}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40872d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# A list of emails with their \"True Label\" for verification\n",
    "test_cases = [\n",
    "    {\n",
    "        \"email\": \"i want to apply offer offer buy this car get a gift free.\",\n",
    "        \"true_label\": \"spam\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "        \"true_label\": \"job_application\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Are you available for a Zoom interview this Wednesday at 3 PM?\",\n",
    "        \"true_label\": \"interview_scheduling\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"The hiring committee has finalized the selection for the Senior Lead role.\",\n",
    "        \"true_label\": \"candidate_selection\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"We need to open a new requisition for the Marketing Manager headcount.\",\n",
    "        \"true_label\": \"new_requisition\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Claim your inheritance! We just need your bank details to send the funds.\",\n",
    "        \"true_label\": \"spam\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Randomize the test order\n",
    "random.shuffle(test_cases)\n",
    "\n",
    "print(f\"{'TRUE LABEL':<25} | {'PREDICTED':<25} | {'STATUS'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for case in test_cases:\n",
    "    text = case[\"email\"]\n",
    "    true_lbl = case[\"true_label\"]\n",
    "    \n",
    "    # Get prediction from your trained classifier\n",
    "    predicted_lbl = classifier.predict([text])[0]\n",
    "    \n",
    "    # Check if the model was correct\n",
    "    status = \"‚úÖ CORRECT\" if predicted_lbl == true_lbl else \"‚ùå WRONG\"\n",
    "    \n",
    "    print(f\"{true_lbl:<25} | {predicted_lbl:<25} | {status}\")\n",
    "    if status == \"‚ùå WRONG\":\n",
    "        print(f\"   ‚îî‚îÄ Text: \\\"{text}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" for the offer offer buy this car get a gift free.test_email \"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")  \n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab72771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh test list\n",
    "test_emails = [\n",
    "    \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "    \"WINNER! You have a gift waiting. Click here to claim your car offer now!\"\n",
    "]\n",
    "\n",
    "# Use the predict method\n",
    "# This calls prepare_data(is_training=False) internally\n",
    "results = classifier.predict(test_emails)\n",
    "\n",
    "for email, category in zip(test_emails, results):\n",
    "    print(f\"Text: {email[:50]}...\")\n",
    "    print(f\"RESULT: {category}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 1. Save the Keras Model (The neural network weights)\n",
    "# # Using .keras is the modern standard for TensorFlow/Keras\n",
    "# classifier.model.save('improved_ats_model.keras')\n",
    "\n",
    "# # 2. Save the Tokenizer (The dictionary mapping words to numbers)\n",
    "# with open('tokenizer.pkl', 'wb') as handle:\n",
    "#     pickle.dump(classifier.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # 3. Save the Label Encoder (The mapping of numbers back to \"Spam\", \"Job\", etc.)\n",
    "# with open('label_encoder.pkl', 'wb') as handle:\n",
    "#     pickle.dump(classifier.label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# print(\"All components (Model, Tokenizer, Label Encoder) saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f96d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample emails from each category\n",
    "unique_categories = df['category'].unique()\n",
    "print(\"Testing predictions for sample emails from each category:\")\n",
    "for cat in unique_categories:\n",
    "    sample_email = df[df['category'] == cat]['email_text'].sample(1).values[0][:200]  # Take first 200 chars for brevity\n",
    "    predicted = classifier.predict([sample_email])[0]\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(f\"Sample Email: {sample_email}...\")\n",
    "    print(f\"Predicted: {predicted}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # from pydantic_settings import BaseSettings\n",
    "# from ydata_profiling import ProfileReport  \n",
    "# df = pd.read_csv('final_training_data.csv')\n",
    "# profile = ProfileReport(df, title=\"Pandas Profiling Report\")    \n",
    "# profile.to_file(\"final_training_data_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275884f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7a49e",
   "metadata": {},
   "source": [
    "## added L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2  # <--- NEW: Import for regularization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=10000, max_length=500):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean text AND remove the 'cheat words' used to label the data.\n",
    "        This forces the model to learn from context, not just keywords.\n",
    "        \"\"\"\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # --- NEW: THE CHEAT SHEET SCRUBBER ---\n",
    "        # These are the exact words used to create the labels. \n",
    "        # We replace them with [MASK] so the model has to look at the surrounding words.\n",
    "        cheat_words = [\n",
    "            'resume', 'cv', 'interview', 'schedule', 'availability', \n",
    "            'requisition', 'headcount', 'spam', 'unsubscribe', 'click here'\n",
    "        ]\n",
    "        for word in cheat_words:\n",
    "            text = text.replace(word, '') \n",
    "        # -------------------------------------\n",
    "\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        return text\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Added L2 Regularization and reduced complexity.\n",
    "        This penalizes the model for being too confident about simple patterns.\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            # Reduced embedding size to 64 to create a \"bottleneck\"\n",
    "            Embedding(self.max_features, 64, input_length=self.max_length),\n",
    "            \n",
    "            # Added L2 Regularization (kernel_regularizer)\n",
    "            Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01))),\n",
    "            GlobalMaxPooling1D(),\n",
    "            \n",
    "            # Added L2 to Dense layers too\n",
    "            Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dropout(0.6), # Increased Dropout to 60%\n",
    "            \n",
    "            Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dropout(0.6),\n",
    "            \n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, texts, labels, validation_split=0.2, epochs=15, batch_size=32):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=True)\n",
    "        self.build_model()\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=3, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X, y,\n",
    "            validation_split=validation_split,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, texts):\n",
    "        X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "        \n",
    "        # \n",
    "        cm = confusion_matrix(y, predicted_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Confusion Matrix (Regularized Model)')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "\n",
    "# --- RUNNING THE CODE ---\n",
    "# --- CORRECTED DATA LOADING SECTION ---\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv('final_training_data.csv')\n",
    "\n",
    "# 2. Rename columns based on your file structure (Label is 1st, Text is 2nd)\n",
    "# Your snippet shows: column 0 = label, column 1 = text\n",
    "df.columns = ['label', 'text'] \n",
    "\n",
    "# 3. Verify it looks right before continuing\n",
    "print(\"--- Data Preview ---\")\n",
    "print(df.head(2))\n",
    "\n",
    "# 4. Filter and Prepare\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df[df['text'].str.len() > 20] # Remove empty/short rows\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# 5. Split and Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training on {len(X_train)} emails, Testing on {len(X_test)} emails.\")\n",
    "\n",
    "classifier = ImprovedATSEmailClassifier()\n",
    "# Train for 15 epochs since we made the task harder with regularization\n",
    "history = classifier.train(X_train, y_train, epochs=15) \n",
    "\n",
    "# Evaluate\n",
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53642777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" for the offer offer buy this car get a gift free.test_email \"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")  \n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7e1be",
   "metadata": {},
   "source": [
    "# Lightweight GRU architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2415f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=3000, max_length=300):\n",
    "        # Reduced max_features and length to prevent overfitting on small data\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean text: lowercase, remove punctuation, stop words.\"\"\"\n",
    "        text = str(text).lower()\n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        return text\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Lightweight GRU model:\n",
    "        - Lower embedding dim (64)\n",
    "        - SpatialDropout1D to force context learning\n",
    "        - Single GRU layer to reduce parameter count\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            Embedding(self.max_features, 64, input_length=self.max_length),\n",
    "            SpatialDropout1D(0.3), \n",
    "            GRU(64, return_sequences=True),\n",
    "            GlobalMaxPooling1D(), # Picks the most important signals from the GRU\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5), \n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, texts, labels, validation_split=0.2, epochs=10, batch_size=32):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=True)\n",
    "        self.build_model()\n",
    "        \n",
    "        # Handle class imbalance\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        # Paitence reduced to 2 for faster cutoff if overfitting starts\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=2, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X, y,\n",
    "            validation_split=validation_split,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, texts):\n",
    "        X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('final_training_data.csv')\n",
    "    # Basic data cleaning\n",
    "    df.columns = ['category', 'email_text']\n",
    "    df = df.dropna(subset=['email_text', 'category'])\n",
    "    \n",
    "    texts = df['email_text'].tolist()\n",
    "    labels = df['category'].tolist()\n",
    "\n",
    "    # Stratified split ensures classes are balanced in both train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Initialize and Train\n",
    "    classifier = ImprovedATSEmailClassifier(max_features=3000, max_length=300)\n",
    "    history = classifier.train(X_train, y_train, epochs=10)\n",
    "\n",
    "    # Evaluate on unseen data\n",
    "    classifier.evaluate(X_test, y_test)\n",
    "\n",
    "    # Visualizing the Training Process\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss (Look for Divergence)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Test Predictions\n",
    "    sample_emails = [\n",
    "        \"I am interested in the Software Engineer role. Please see my resume.\",\n",
    "        \"URGENT: Win a free car now! Click this link to claim your offer prize!\"\n",
    "    ]\n",
    "    \n",
    "    for email in sample_emails:\n",
    "        pred = classifier.predict([email])[0]\n",
    "        print(f\"Email: {email[:50]}... \\nPredicted: {pred}\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'final_training_data.csv' not found. Please ensure the file is in the same directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample emails from each category\n",
    "unique_categories = df['label'].unique()\n",
    "print(\"Testing predictions for sample emails from each category:\")\n",
    "for cat in unique_categories:\n",
    "    sample_email = df[df['label'] == cat]['text'].sample(1).values[0][:200]  # Take first 200 chars for brevity\n",
    "    predicted = classifier.predict([sample_email])[0]\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(f\"Sample Email: {sample_email}...\")\n",
    "    print(f\"Predicted: {predicted}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78dbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66d54e2",
   "metadata": {},
   "source": [
    "# Using Bert \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch tf-keras accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f6d33",
   "metadata": {},
   "source": [
    "# STEP 0: Install Requirements (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca141bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow transformers scikit-learn pandas matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d0d88",
   "metadata": {},
   "source": [
    "# STEP 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee826691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8eead",
   "metadata": {},
   "source": [
    "# STEP 2: Load & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69baa701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_training_data1.csv\")\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df = df.dropna(subset=[\"label\", \"text\"])\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Original Class Distribution:\")\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d874fd",
   "metadata": {},
   "source": [
    "# STEP 3: Balance Dataset (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72261c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df.groupby(\"label\").apply(\n",
    "    lambda x: x.sample(min(len(x), 450), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Class Distribution:\")\n",
    "print(df_balanced[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef840e",
   "metadata": {},
   "source": [
    "# STEP 4: Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155095cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_balanced[\"label_encoded\"] = label_encoder.fit_transform(df_balanced[\"label\"])\n",
    "\n",
    "num_classes = df_balanced[\"label_encoded\"].nunique()\n",
    "print(\"\\nClasses:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87089632",
   "metadata": {},
   "source": [
    "# STEP 5: Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df_balanced[\"text\"],\n",
    "    df_balanced[\"label_encoded\"],\n",
    "    test_size=0.3,\n",
    "    stratify=df_balanced[\"label_encoded\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.33,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8a6f9",
   "metadata": {},
   "source": [
    "# STEP 6: Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5d9c8",
   "metadata": {},
   "source": [
    "# STEP 7: Tokenization Function (BERT Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=256):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = bert_encode(X_train, tokenizer)\n",
    "val_enc   = bert_encode(X_val, tokenizer)\n",
    "test_enc  = bert_encode(X_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495fc35",
   "metadata": {},
   "source": [
    "# STEP 8: Compute Class Weights (IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb529a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a965e3",
   "metadata": {},
   "source": [
    "# STEP 9: Load BERT Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_classes,\n",
    "    from_pt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6b462",
   "metadata": {},
   "source": [
    "# STEP 10: Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4101b",
   "metadata": {},
   "source": [
    "# STEP 11: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a061ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dict(train_enc),\n",
    "    y_train,\n",
    "    validation_data=(dict(val_enc), y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    class_weight=class_weight_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021279e",
   "metadata": {},
   "source": [
    "# STEP 12: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(dict(test_enc))\n",
    "y_pred = np.argmax(test_preds.logits, axis=1)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf6049",
   "metadata": {},
   "source": [
    "# STEP 13: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b975b1",
   "metadata": {},
   "source": [
    "# STEP 14: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f635027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958e0c7",
   "metadata": {},
   "source": [
    "# STEP 15: Predict on New Emails (With Confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_email(text):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    logits = model(enc).logits\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    idx = tf.argmax(probs, axis=1).numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"predicted_class\": label_encoder.classes_[idx],\n",
    "        \"confidence\": float(probs[0][idx])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9745db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_email' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m sample_email = \u001b[33m\"\"\"\u001b[39m\u001b[33mSubject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33mDear Customer,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33mSecurity Team\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33mCustomer Support Department\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_email\u001b[49m(sample_email))\n",
      "\u001b[31mNameError\u001b[39m: name 'predict_email' is not defined"
     ]
    }
   ],
   "source": [
    "sample_email = \"\"\"Subject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\n",
    "\n",
    "Dear Customer,\n",
    "\n",
    "We detected suspicious activity on your account. For your safety, we have temporarily limited access to your account.\n",
    "\n",
    "To restore full access, please verify your details immediately by clicking the secure link below:\n",
    "\n",
    "üëâ Verify Your Account Now\n",
    "\n",
    "Failure to verify within 24 hours may result in permanent suspension of your account.\n",
    "\n",
    "Thank you for your prompt attention.\n",
    "\n",
    "Sincerely,\n",
    "Security Team\n",
    "Customer Support Department\"\"\"\n",
    "print(predict_email(sample_email))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841cb03",
   "metadata": {},
   "source": [
    "# STEP 16: Save Model & Tokenizer (IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100599ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bert_ats_model\")\n",
    "tokenizer.save_pretrained(\"bert_ats_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b23d3",
   "metadata": {},
   "source": [
    "# Complete code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d69a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.13.0\n",
      "Uninstalling keras-3.13.0:\n",
      "  Successfully uninstalled keras-3.13.0\n",
      "Found existing installation: transformers 4.57.3\n",
      "Uninstalling transformers-4.57.3:\n",
      "  Successfully uninstalled transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.32.5)\n",
      "Requirement already satisfied: setuptools in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.16.2)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.2->tensorflow==2.16.2)\n",
      "  Using cached keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.1.4)\n",
      "Requirement already satisfied: filelock in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\talentprism\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\talentprism\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.45.1)\n",
      "Requirement already satisfied: rich in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (14.2.0)\n",
      "Requirement already satisfied: namex in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.0)\n",
      "Requirement already satisfied: optree in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.18.0)\n",
      "Requirement already satisfied: colorama in e:\\talentprism\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in e:\\talentprism\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\talentprism\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\talentprism\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\talentprism\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.2)\n",
      "Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: keras, transformers, tensorflow\n",
      "\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ---------------------------------------- 3/3 [tensorflow]\n",
      "\n",
      "Successfully installed keras-3.13.0 tensorflow-2.16.2 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.20.1 requires tensorflow<2.21,>=2.20, but you have tensorflow 2.16.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall tensorflow keras transformers -y\n",
    "%pip install tensorflow==2.16.2 transformers\n",
    "\n",
    "# %pip install tensorflow==2.12.1 keras==2.12.0 transformers==4.37.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a0b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "label\n",
      "job_application         618\n",
      "spam                    523\n",
      "new_requisition         515\n",
      "interview_scheduling    510\n",
      "candidate_selection     454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced Class Distribution:\n",
      "label\n",
      "candidate_selection     450\n",
      "interview_scheduling    450\n",
      "job_application         450\n",
      "new_requisition         450\n",
      "spam                    450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: ['candidate_selection' 'interview_scheduling' 'job_application'\n",
      " 'new_requisition' 'spam']\n",
      "\n",
      "Train: 1575, Val: 452, Test: 223\n",
      "\n",
      "Class Weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 1628s 16s/step - loss: 0.6892 - accuracy: 0.8368 - val_loss: 0.1174 - val_accuracy: 0.9934 - lr: 2.0000e-05\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 1573s 16s/step - loss: 0.0709 - accuracy: 0.9962 - val_loss: 0.0486 - val_accuracy: 0.9912 - lr: 2.0000e-05\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 1667s 17s/step - loss: 0.0270 - accuracy: 0.9987 - val_loss: 0.0172 - val_accuracy: 0.9956 - lr: 2.0000e-05\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000 \n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-06.\n",
      "99/99 [==============================] - 1557s 16s/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9956 - lr: 2.0000e-05\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 1550s 16s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9956 - lr: 6.0000e-06\n",
      "7/7 [==============================] - 63s 9s/step\n",
      "\n",
      "--- Classification Report ---\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      " candidate_selection     1.0000    1.0000    1.0000        45\n",
      "interview_scheduling     0.9778    1.0000    0.9888        44\n",
      "     job_application     1.0000    1.0000    1.0000        45\n",
      "     new_requisition     1.0000    1.0000    1.0000        45\n",
      "                spam     1.0000    0.9773    0.9885        44\n",
      "\n",
      "            accuracy                         0.9955       223\n",
      "           macro avg     0.9956    0.9955    0.9955       223\n",
      "        weighted avg     0.9956    0.9955    0.9955       223\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'job_application', 'confidence': 0.974174976348877}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn while saving (showing 5 of 422). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_ats_model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_ats_model1\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert_ats_tokenizer1\\\\tokenizer_config.json',\n",
       " 'bert_ats_tokenizer1\\\\special_tokens_map.json',\n",
       " 'bert_ats_tokenizer1\\\\vocab.txt',\n",
       " 'bert_ats_tokenizer1\\\\added_tokens.json',\n",
       " 'bert_ats_tokenizer1\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================== COMPLETE BERT-BASED ATS EMAIL CLASSIFIER =====================\n",
    "# Copy‚ÄìPaste Ready | Includes EarlyStopping, ReduceLROnPlateau, Class Weights,\n",
    "# Dataset Balancing, Stratified Splits, Overfitting Controls, and Safe BERT Loading\n",
    "# ==================================================================================\n",
    "\n",
    "# ---------- STEP 0: IMPORT LIBRARIES ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# ---------- STEP 1: LOAD & CLEAN DATA ----------\n",
    "df = pd.read_csv(\"final_training_data1.csv\")\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df = df.dropna(subset=[\"label\", \"text\"])\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Original Class Distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "\n",
    "# ---------- STEP 2: BALANCE DATASET (ANTI-IMBALANCE) ----------\n",
    "df_balanced = df.groupby(\"label\").apply(\n",
    "    lambda x: x.sample(min(len(x), 450), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Class Distribution:\")\n",
    "print(df_balanced[\"label\"].value_counts())\n",
    "\n",
    "\n",
    "# ---------- STEP 3: LABEL ENCODING ----------\n",
    "label_encoder = LabelEncoder()\n",
    "df_balanced[\"label_encoded\"] = label_encoder.fit_transform(df_balanced[\"label\"])\n",
    "\n",
    "num_classes = df_balanced[\"label_encoded\"].nunique()\n",
    "print(\"\\nClasses:\", label_encoder.classes_)\n",
    "\n",
    "\n",
    "# ---------- STEP 4: TRAIN / VAL / TEST SPLIT (STRATIFIED) ----------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df_balanced[\"text\"],\n",
    "    df_balanced[\"label_encoded\"],\n",
    "    test_size=0.3,\n",
    "    stratify=df_balanced[\"label_encoded\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.33,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "\n",
    "# ---------- STEP 5: LOAD BERT TOKENIZER ----------\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# ---------- STEP 6: TOKENIZATION FUNCTION ----------\n",
    "def bert_encode(texts, tokenizer, max_len=256):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "train_enc = bert_encode(X_train, tokenizer)\n",
    "val_enc   = bert_encode(X_val, tokenizer)\n",
    "test_enc  = bert_encode(X_test, tokenizer)\n",
    "\n",
    "\n",
    "# ---------- STEP 7: CLASS WEIGHTS (ANTI-IMBALANCE) ----------\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Weights:\", class_weight_dict)\n",
    "\n",
    "\n",
    "# ---------- STEP 8: LOAD BERT MODEL (SAFE LOAD FIX) ----------\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_classes,\n",
    "    from_pt=True  # fixes safetensors / safe_open error\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 9: COMPILE MODEL (LOW LR = LESS OVERFITTING) ----------\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 10: CALLBACKS ----------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 11: TRAIN MODEL ----------\n",
    "history = model.fit(\n",
    "    dict(train_enc),\n",
    "    y_train,\n",
    "    validation_data=(dict(val_enc), y_val),\n",
    "    epochs=5,          # BERT converges fast\n",
    "    batch_size=16,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 12: EVALUATE ON TEST SET ----------\n",
    "test_preds = model.predict(dict(test_enc))\n",
    "y_pred = np.argmax(test_preds.logits, axis=1)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "\n",
    "# ---------- STEP 13: CONFUSION MATRIX ----------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- STEP 14: TRAINING CURVES ----------\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- STEP 15: CONFIDENCE-AWARE PREDICTION ----------\n",
    "def predict_email(text, threshold=0.7):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    logits = model(enc).logits\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    idx = tf.argmax(probs, axis=1).numpy()[0]\n",
    "    confidence = float(probs[0][idx])\n",
    "\n",
    "    result = {\n",
    "        \"predicted_class\": label_encoder.classes_[idx],\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "    if confidence < threshold:\n",
    "        result[\"warning\"] = \"Low confidence prediction\"\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------- STEP 16: SAMPLE PREDICTION ----------\n",
    "print(predict_email(\"Dear HR, I am applying for the Data Scientist position.\"))\n",
    "\n",
    "\n",
    "# ---------- STEP 17: SAVE MODEL & TOKENIZER ----------\n",
    "model.save(\"bert_ats_model1\")\n",
    "tokenizer.save_pretrained(\"bert_ats_tokenizer1\")\n",
    "\n",
    "# ===================== END OF COMPLETE CODE =====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5598fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'spam', 'confidence': 0.9041456580162048}\n"
     ]
    }
   ],
   "source": [
    "sample_email = \"\"\"Subject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\n",
    "\n",
    "Dear Customer,\n",
    "\n",
    "We detected suspicious activity on your account. For your safety, we have temporarily limited access to your account.\n",
    "\n",
    "To restore full access, please verify your details immediately by clicking the secure link below:\n",
    "\n",
    "üëâ Verify Your Account Now\n",
    "\n",
    "Failure to verify within 24 hours may result in permanent suspension of your account.\n",
    "\n",
    "Thank you for your prompt attention.\n",
    "\n",
    "Sincerely,\n",
    "Security Team\n",
    "Customer Support Department\"\"\"\n",
    "print(predict_email(sample_email))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab82b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'job_application', 'confidence': 0.974174976348877}\n"
     ]
    }
   ],
   "source": [
    "print(predict_email(\"Dear HR, I am applying for the Data Scientist position.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c168413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CATEGORY: JOB_APPLICATION ================\n",
      "\n",
      "Email: Dear HR, I am writing to apply for the Data Scientist position at your organization.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9850926995277405}\n",
      "\n",
      "Email: Please find attached my resume for the Software Engineer role.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9893084764480591}\n",
      "\n",
      "Email: I am interested in the open Machine Learning Engineer position and would like to apply.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9758139252662659}\n",
      "\n",
      "================ CATEGORY: INTERVIEW_SCHEDULING ================\n",
      "\n",
      "Email: Dear Candidate, your interview is scheduled for Monday at 11 AM. Please confirm.\n",
      "Prediction: {'predicted_class': 'interview_scheduling', 'confidence': 0.9063847661018372}\n",
      "\n",
      "Email: We would like to schedule a technical interview for the next round.\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.4196885824203491, 'warning': 'Low confidence prediction'}\n",
      "\n",
      "Email: Kindly let us know your availability for the interview this week.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.8914213180541992}\n",
      "\n",
      "================ CATEGORY: CANDIDATE_SELECTION ================\n",
      "\n",
      "Email: Congratulations! You have been selected for the Data Analyst role.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.7146317958831787}\n",
      "\n",
      "Email: We are pleased to inform you that you have cleared all interview rounds.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.8394487500190735}\n",
      "\n",
      "Email: You have been shortlisted and selected. Our HR team will contact you shortly.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.5683006644248962, 'warning': 'Low confidence prediction'}\n",
      "\n",
      "================ CATEGORY: SPAM ================\n",
      "\n",
      "Email: URGENT!!! You have won a free iPhone. Click here to claim now!\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9899371862411499}\n",
      "\n",
      "Email: Congratulations, you are selected for a cash prize. Act fast!\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9864894151687622}\n",
      "\n",
      "Email: Limited time offer!!! Earn money from home with zero investment.\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9747705459594727}\n"
     ]
    }
   ],
   "source": [
    "# ---------------- SAMPLE EMAILS FOR EACH CATEGORY ----------------\n",
    "\n",
    "sample_emails = {\n",
    "    \"job_application\": [\n",
    "        \"Dear HR, I am writing to apply for the Data Scientist position at your organization.\",\n",
    "        \"Please find attached my resume for the Software Engineer role.\",\n",
    "        \"I am interested in the open Machine Learning Engineer position and would like to apply.\"\n",
    "    ],\n",
    "\n",
    "    \"interview_scheduling\": [\n",
    "        \"Dear Candidate, your interview is scheduled for Monday at 11 AM. Please confirm.\",\n",
    "        \"We would like to schedule a technical interview for the next round.\",\n",
    "        \"Kindly let us know your availability for the interview this week.\"\n",
    "    ],\n",
    "\n",
    "    \"candidate_selection\": [\n",
    "        \"Congratulations! You have been selected for the Data Analyst role.\",\n",
    "        \"We are pleased to inform you that you have cleared all interview rounds.\",\n",
    "        \"You have been shortlisted and selected. Our HR team will contact you shortly.\"\n",
    "    ],\n",
    "\n",
    "    \"spam\": [\n",
    "        \"URGENT!!! You have won a free iPhone. Click here to claim now!\",\n",
    "        \"Congratulations, you are selected for a cash prize. Act fast!\",\n",
    "        \"Limited time offer!!! Earn money from home with zero investment.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ---------------- RUN PREDICTIONS ----------------\n",
    "\n",
    "for category, emails in sample_emails.items():\n",
    "    print(f\"\\n================ CATEGORY: {category.upper()} ================\")\n",
    "    \n",
    "    for email in emails:\n",
    "        result = predict_email(email)\n",
    "        print(f\"\\nEmail: {email}\")\n",
    "        print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b03ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# # Encode labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "# num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# # Split data\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "#     df['email_text'].tolist(), df['category_encoded'].tolist(), test_size=0.2, random_state=42, stratify=df['category_encoded']\n",
    "# )\n",
    "\n",
    "# # Custom Dataset class\n",
    "# class EmailDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.texts[idx]\n",
    "#         label = self.labels[idx]\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_len,\n",
    "#             return_token_type_ids=False,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             return_attention_mask=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'labels': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# # Load BERT tokenizer and model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# # Create datasets\n",
    "# train_dataset = EmailDataset(train_texts, train_labels, tokenizer)\n",
    "# test_dataset = EmailDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# # Training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,  # Fewer epochs for BERT to avoid overfitting\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=10,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "# )\n",
    "\n",
    "# # Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate\n",
    "# trainer.evaluate()\n",
    "\n",
    "# # Function to predict\n",
    "# def predict_bert(text):\n",
    "#     encoding = tokenizer.encode_plus(\n",
    "#         text,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=512,\n",
    "#         return_token_type_ids=False,\n",
    "#         padding='max_length',\n",
    "#         truncation=True,\n",
    "#         return_attention_mask=True,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**encoding)\n",
    "#         predictions = torch.argmax(outputs.logits, dim=1)\n",
    "#     return label_encoder.inverse_transform(predictions.numpy())[0]\n",
    "\n",
    "# # Test on sample\n",
    "# test_email = \"I am applying for the data analyst position. Attached is my resume.\"\n",
    "# print(f\"BERT Predicted Category: {predict_bert(test_email)}\")\n",
    "\n",
    "# # Test on all categories\n",
    "# unique_categories = df['category'].unique()\n",
    "# print(\"BERT Testing predictions for sample emails from each category:\")\n",
    "# for cat in unique_categories:\n",
    "#     sample_email = df[df['category'] == cat]['email_text'].sample(1).values[0][:200]\n",
    "#     predicted = predict_bert(sample_email)\n",
    "#     print(f\"Category: {cat}\")\n",
    "#     print(f\"Predicted: {predicted}\")\n",
    "#     print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bert_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
