{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7166ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bc923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2c59e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: Site Manager for Downtown High-Rise\\r\\n\\r\\nHi Team,\\r\\n\\r\\nWe just broke ground on the Millennium Tower project downtown, and we need a Senior Site Manager to oversee the structural phase.\\r\\n\\r\\nThe candidate needs a minimum of 10 years in commercial high-rise construction. They must be OSHA 30 certified and have experience managing subcontractors for concrete and steel. The job involves being on-site at 6 AM every day, coordinating deliveries, and ensuring safety compliance. We need someone authoritative who can keep the timeline on track despite weather or supply delays.\\r\\n\\r\\nThis is a 24-month contract with the possibility of extension. We need someone to start in two weeks. Please check their references regarding timeline management specifically.\\r\\n\\r\\nBest regards,\\r\\n\\r\\nTom O'Malley Project Director BuildRight Construction\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5).head()\n",
    "df['text'][1762]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6acbfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aabd426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2576 entries, 0 to 2575\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   2576 non-null   object\n",
      " 1   text    2576 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 40.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea076b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data cleaning \n",
    "# 2. Exploratory Data Analysis \n",
    "# 3. text preprocessing\n",
    "# 4. Model building\n",
    "# 5. Model evaluation\n",
    "# 6. Improvement and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169a8ed",
   "metadata": {},
   "source": [
    "## 1. Data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07e84e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>new_requisition</td>\n",
       "      <td>Hello,\\r\\n\\r\\nStonePeak Construction is seekin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>interview_scheduling</td>\n",
       "      <td>Interview Tomorrow @ 11 AM - Quick Reminder\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: URGENT!! You have been selected to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>interview_scheduling</td>\n",
       "      <td>Interview Scheduled ‚Äì Network Security Analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>new_requisition</td>\n",
       "      <td>Legal Secretary - Family Law Practice\\r\\nDear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                               text\n",
       "1374       new_requisition  Hello,\\r\\n\\r\\nStonePeak Construction is seekin...\n",
       "2130  interview_scheduling  Interview Tomorrow @ 11 AM - Quick Reminder\\r\\...\n",
       "108                   spam  Subject: URGENT!! You have been selected to re...\n",
       "1432  interview_scheduling  Interview Scheduled ‚Äì Network Security Analyst...\n",
       "2243       new_requisition  Legal Secretary - Family Law Practice\\r\\nDear ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15b755",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7035bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImprovedATSEmailClassifier:\n",
    "#     def __init__(self, max_features=10000, max_length=500):\n",
    "#         self.max_features = max_features\n",
    "#         self.max_length = max_length\n",
    "#         self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.model = None\n",
    "#         self.num_classes = None\n",
    "\n",
    "#     def preprocess_text(self, text):\n",
    "#         \"\"\"Clean text: lowercase, remove punctuation, stop words.\"\"\"\n",
    "#         text = text.lower()\n",
    "#         text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "#         text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "#         return text\n",
    "\n",
    "#     def prepare_data(self, texts, labels):\n",
    "#         \"\"\"Prepare data with preprocessing.\"\"\"\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         # self.tokenizer.fit_on_texts(texts)\n",
    "#         if is_training:\n",
    "#             self.tokenizer.fit_on_texts(texts)\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         y = self.label_encoder.fit_transform(labels)\n",
    "#         self.num_classes = len(np.unique(y))\n",
    "#         return X, y\n",
    "\n",
    "#     def build_model(self):\n",
    "#         \"\"\"Improved model: Bidirectional LSTM for better sequence handling.\"\"\"\n",
    "#         model = Sequential([\n",
    "#             Embedding(self.max_features, 128, input_length=self.max_length),\n",
    "#             Bidirectional(LSTM(64, return_sequences=True)),  # Better for context\n",
    "#             GlobalMaxPooling1D(),\n",
    "#             Dense(128, activation='relu'),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(64, activation='relu'),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(self.num_classes, activation='softmax')\n",
    "#         ])\n",
    "#         model.compile(\n",
    "#             optimizer='adam',\n",
    "#             loss='sparse_categorical_crossentropy',\n",
    "#             metrics=['accuracy']\n",
    "#         )\n",
    "#         self.model = model\n",
    "#         return model\n",
    "\n",
    "#     def train(self, texts, labels, validation_split=0.2, epochs=10, batch_size=32):\n",
    "#         X, y = self.prepare_data(texts, labels)\n",
    "#         self.build_model()\n",
    "        \n",
    "#         # Class weights for imbalance\n",
    "#         class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "#         class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "#         # Early stopping to prevent overfitting\n",
    "#         early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "#         history = self.model.fit(\n",
    "#             X, y,\n",
    "#             validation_split=validation_split,\n",
    "#             epochs=10,\n",
    "#             batch_size=batch_size,\n",
    "#             class_weight=class_weight_dict,\n",
    "#             callbacks=[early_stop],\n",
    "#             verbose=1\n",
    "#         )\n",
    "#         return history\n",
    "\n",
    "#     def predict(self, texts):\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "#         return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "#     def evaluate(self, texts, labels):\n",
    "#         texts = [self.preprocess_text(t) for t in texts]\n",
    "#         sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "#         y = self.label_encoder.transform(labels)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "#         print(\"Classification Report:\")\n",
    "#         print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "        \n",
    "#         cm = confusion_matrix(y, predicted_classes)\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#                    xticklabels=self.label_encoder.classes_,\n",
    "#                    yticklabels=self.label_encoder.classes_)\n",
    "#         plt.title('Confusion Matrix')\n",
    "#         plt.ylabel('Actual')\n",
    "#         plt.xlabel('Predicted')\n",
    "#         plt.xticks(rotation=45)\n",
    "#         plt.yticks(rotation=0)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf225f",
   "metadata": {},
   "source": [
    "# LSTM MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294301d",
   "metadata": {},
   "source": [
    "## This is the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, Bidirectional\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from tensorflow.keras.layers import Attention\n",
    "\n",
    "\n",
    "# # Download stopwords if needed\n",
    "# # nltk.download('stopwords')\n",
    "# # stop_words = set(stopwords.words('english'))\n",
    "# try:\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "# except LookupError:\n",
    "#     nltk.download('stopwords')\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# class ImprovedATSEmailClassifier:\n",
    "#     def __init__(self, max_features=20000, max_length=500):\n",
    "#         self.max_features = max_features\n",
    "#         self.max_length = max_length\n",
    "#         self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         self.model = None\n",
    "#         self.num_classes = None\n",
    "\n",
    "#     def preprocess_text(self, text):\n",
    "#         # Convert to string and cap length (PROTECTION STEP)\n",
    "#         text = str(text)[:5000]\n",
    "\n",
    "#         # Normalize\n",
    "#         text = text.lower()\n",
    "\n",
    "#         # Keep meaningful characters (emails, %, numbers)\n",
    "#         text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "\n",
    "#         # Optional: keep stopwords for LSTM context (recommended)\n",
    "#         # If you keep stopword removal, do it AFTER truncation\n",
    "#         text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "#         return text\n",
    "\n",
    "\n",
    "#     def prepare_data(self, texts, labels=None, is_training=True):\n",
    "#         \"\"\"Prepare data with preprocessing. Added is_training logic.\"\"\"\n",
    "#         processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "#         # FIX: Only fit the dictionary during the training phase\n",
    "#         if is_training:\n",
    "#             self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "#         sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "#         X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "#         if labels is not None:\n",
    "#             if is_training:\n",
    "#                 y = self.label_encoder.fit_transform(labels)\n",
    "#                 self.num_classes = len(np.unique(y))\n",
    "#             else:\n",
    "#                 unknown_labels = set(labels) - set(self.label_encoder.classes_)\n",
    "#                 if unknown_labels:\n",
    "#                     raise ValueError(\n",
    "#                         f\"Unknown label(s) detected: {unknown_labels}. \"\n",
    "#                         \"Model was not trained on these classes.\"\n",
    "#                 )\n",
    "#                 y = self.label_encoder.transform(labels)\n",
    "#             return X, y\n",
    "#         return X\n",
    "\n",
    "#     def build_model(self):\n",
    "#         # Input layer\n",
    "#         inputs = Input(shape=(self.max_length,))\n",
    "\n",
    "#         # Embedding\n",
    "#         x = Embedding(\n",
    "#             input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "#             output_dim=128\n",
    "#         )(inputs)\n",
    "\n",
    "#         # BiLSTM\n",
    "#         x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "#         # Self-attention\n",
    "#         x = Attention()([x, x])\n",
    "\n",
    "#         # Reduce sequence dimension\n",
    "#         x = tf.reduce_mean(x, axis=1)\n",
    "\n",
    "#         # Dense layers\n",
    "#         x = Dense(128, activation='relu')(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "#         x = Dense(64, activation='relu')(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "\n",
    "#         # Output\n",
    "#         outputs = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "#         # Build model\n",
    "#         model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#         model.compile(\n",
    "#             optimizer='adam',\n",
    "#             loss='sparse_categorical_crossentropy',\n",
    "#             metrics=['accuracy']\n",
    "#         )\n",
    "\n",
    "#         self.model = model\n",
    "#         return model\n",
    "    \n",
    "#     def train(self, X_train, y_train,X_val,epochs=10,batch_size=32):\n",
    "#          # Prepare training data\n",
    "#         X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        \n",
    "#         # Prepare validation data (NO fitting here)\n",
    "#         X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "#         # 2. Debug label mapping\n",
    "#         mapping = dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))\n",
    "#         print(f\"\\n[DEBUG] Label Mapping is: {mapping}\")\n",
    "        \n",
    "#         # 3. Build and compile the model\n",
    "#         self.build_model()\n",
    "        \n",
    "#         # 4. Calculate class weights for balance\n",
    "#         class_weights = compute_class_weight(\n",
    "#             class_weight='balanced',\n",
    "#             classes=np.unique(y_tr),\n",
    "#             y=y_tr\n",
    "#         )\n",
    "#         class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "#         # 5. Setup Early Stopping to prevent overfitting\n",
    "#         early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss', \n",
    "#             patience=3, \n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "        \n",
    "#          # Train\n",
    "#         history = self.model.fit(\n",
    "#             X_tr,\n",
    "#             y_tr,\n",
    "#             validation_data=(X_v, y_v),\n",
    "#             epochs=epochs,\n",
    "#             batch_size=batch_size,\n",
    "#             class_weight=class_weight_dict,\n",
    "#             callbacks=[early_stop],\n",
    "#             verbose=1\n",
    "#         )\n",
    "#         return history\n",
    "\n",
    "#     def predict(self, texts):\n",
    "#         # Pass is_training=False to keep the tokenizer dictionary locked\n",
    "#         X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "#         return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "#     # def evaluate(self, texts, labels):\n",
    "#     #     # Pass is_training=False for evaluation\n",
    "#     #     X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "#     #     predictions = self.model.predict(X)\n",
    "#     #     predicted_classes = np.argmax(predictions, axis=1)\n",
    "#     #     print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "    \n",
    "#     # def predict_probabilities(self, texts):\n",
    "#     #     X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#     #     preds = self.model.predict(X)\n",
    "#     #     for i, p in enumerate(preds):\n",
    "#     #         print(f\"Text: {texts[i][:50]}...\")\n",
    "#     #         for j, class_name in enumerate(self.label_encoder.classes_):\n",
    "#     #             print(f\" - {class_name}: {p[j]*100:.2f}%\")\n",
    "\n",
    "#     def evaluate(self, texts, labels):\n",
    "#         \"\"\"Prints classification report and plots a Confusion Matrix heatmap.\"\"\"\n",
    "#         X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "#         predictions = self.model.predict(X)\n",
    "#         predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "#         # 1. Classification Report\n",
    "#         print(\"\\n\" + \"=\"*30)\n",
    "#         print(\"CLASSIFICATION REPORT\")\n",
    "#         print(\"=\"*30)\n",
    "#         print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_, digits =4))\n",
    "        \n",
    "#         # 2. Confusion Matrix\n",
    "#         cm = confusion_matrix(y, predicted_classes)\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "#                     xticklabels=self.label_encoder.classes_, \n",
    "#                     yticklabels=self.label_encoder.classes_)\n",
    "#         plt.title('Confusion Matrix: Actual vs. Predicted')\n",
    "#         plt.ylabel('Actual Category')\n",
    "#         plt.xlabel('Predicted Category')\n",
    "#         plt.show()\n",
    "\n",
    "#     def predict_probabilities(self, texts):\n",
    "#         \"\"\"Shows exactly how confident the model is for every category.\"\"\"\n",
    "#         X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "#         preds = self.model.predict(X)\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*30)\n",
    "#         print(\"CONFIDENCE SCORES\")\n",
    "#         print(\"=\"*30)\n",
    "#         for i, p in enumerate(preds):\n",
    "#             print(f\"Text snippet: '{texts[i][:60]}...'\")\n",
    "#             # Sort by highest confidence\n",
    "#             sorted_indices = np.argsort(p)[::-1]\n",
    "#             for idx in sorted_indices:\n",
    "#                 class_name = self.label_encoder.classes_[idx]\n",
    "#                 confidence = p[idx] * 100\n",
    "#                 print(f\"  --> {class_name}: {confidence:.2f}%\")\n",
    "#             print(\"-\" * 20)\n",
    "\n",
    "# # Load data from CSV (assuming columns are 'category' and the email text column; adjust if needed)\n",
    "# # df = pd.read_csv('final_training_data.csv')\n",
    "# # Load data\n",
    "# df = pd.read_csv('final_training_data1.csv')\n",
    "# df.columns = ['label', 'text']\n",
    "\n",
    "# # 1Ô∏è‚É£ Drop NaNs FIRST\n",
    "# df = df.dropna(subset=['text', 'label'])\n",
    "\n",
    "# # 2Ô∏è‚É£ Drop duplicate emails\n",
    "# df = df.drop_duplicates(subset=['text'])\n",
    "\n",
    "# # 3Ô∏è‚É£ Shuffle dataset (important before capping)\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # 4Ô∏è‚É£ Cap samples per category (balanced dataset)\n",
    "# MAX_PER_CLASS = 450\n",
    "# df = df.groupby('label').head(MAX_PER_CLASS)\n",
    "\n",
    "# # 5Ô∏è‚É£ Verify distribution\n",
    "# print(\"Final label distribution:\")\n",
    "# print(df['label'].value_counts())\n",
    "\n",
    "# # df = df.dropna(subset=['text'])\n",
    "# texts = df['text'].tolist()\n",
    "# labels = df['label'].tolist()\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# # Train model\n",
    "# classifier = ImprovedATSEmailClassifier()\n",
    "# history = classifier.train(X_train, y_train, epochs=10)\n",
    "\n",
    "# # Evaluate\n",
    "# classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# # Plot training history\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Model Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Test prediction\n",
    "# # test_email = \"I am applying for the data analyst position. Attached is my resume.\"\n",
    "# # print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")\n",
    "# # test_email = \"I am applying for the offer offer buy this car get a gift free. Attached is my resume.\"\n",
    "# # print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") \n",
    "\n",
    "# # ... (Previous training code) ...\n",
    "\n",
    "# # 1. Run evaluation (This will now show the Confusion Matrix plot)\n",
    "# # classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# # 2. Test specific emails with CONFIDENCE NUMBERS\n",
    "# test_emails = [\n",
    "#     \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "#     \"I am applying for the offer offer buy this car get a gift free. Attached is my resume.\"\n",
    "# ]\n",
    "\n",
    "# classifier.predict_probabilities(test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ff17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Embedding, LSTM,\n",
    "    Bidirectional, Attention,\n",
    "    GlobalAveragePooling1D, Input\n",
    ")\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a12e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=8000, max_length=500):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    # def preprocess_text(self, text):\n",
    "    #     text = str(text)[:5000]\n",
    "    #     text = text.lower()\n",
    "    #     text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "    #     text = ' '.join(w for w in text.split() if w not in stop_words)\n",
    "    #     return text\n",
    "    def preprocess_text(self, text):\n",
    "        text = str(text)[:5000]\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        texts = [self.preprocess_text(t) for t in texts]\n",
    "\n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "\n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                unknown = set(labels) - set(self.label_encoder.classes_)\n",
    "                if unknown:\n",
    "                    raise ValueError(f\"Unknown labels detected: {unknown}\")\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=(self.max_length,))\n",
    "        x = Embedding(\n",
    "            input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "            output_dim=128\n",
    "        )(inputs)\n",
    "\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        # x = Attention()([x, x])\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        # x = Dense(64, activation='relu')(x)\n",
    "        # x = Dropout(0.3)(x)\n",
    "\n",
    "        outputs = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        self.model = Model(inputs, outputs)\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=15, batch_size=32):\n",
    "        X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_tr),\n",
    "            y=y_tr\n",
    "        )\n",
    "        class_weight = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            \n",
    "            patience=4,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        return self.model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_v, y_v),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        preds = np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "        print(classification_report(\n",
    "            y, preds,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            digits=4\n",
    "        ))\n",
    "\n",
    "        cm = confusion_matrix(y, preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.show()\n",
    "\n",
    "    def predict_probabilities(self, texts):\n",
    "        X = self.prepare_data(texts, is_training=False)\n",
    "        preds = self.model.predict(X)\n",
    "\n",
    "        for i, p in enumerate(preds):\n",
    "            print(f\"\\nText: {texts[i][:60]}...\")\n",
    "            for idx in np.argsort(p)[::-1]:\n",
    "                print(f\"{self.label_encoder.classes_[idx]}: {p[idx]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data1.csv')\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "df = df.dropna(subset=['label', 'text'])\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "df = df.groupby('label').head(450)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "# )\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    "# )\n",
    "\n",
    "# classifier = ImprovedATSEmailClassifier()\n",
    "# history = classifier.train(X_train, y_train, X_val, y_val, epochs=10)\n",
    "# classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "classifier = ImprovedATSEmailClassifier()\n",
    "history = classifier.train(X_train, y_train, X_val, y_val, epochs=15)\n",
    "classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b943fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SAVE MODEL ARTIFACTS (RUN AFTER TRAINING) =====\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "MODEL_DIR = \"model2\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# 1Ô∏è‚É£ Save trained Keras model\n",
    "classifier.model.save(os.path.join(MODEL_DIR, \"ats_email_model.keras\"))\n",
    "\n",
    "# 2Ô∏è‚É£ Save tokenizer\n",
    "with open(os.path.join(MODEL_DIR, \"tokenizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(classifier.tokenizer, f)\n",
    "\n",
    "# 3Ô∏è‚É£ Save label encoder\n",
    "with open(os.path.join(MODEL_DIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(classifier.label_encoder, f)\n",
    "\n",
    "# 4Ô∏è‚É£ Save config (important for inference)\n",
    "config = {\n",
    "    \"max_features\": classifier.max_features,\n",
    "    \"max_length\": classifier.max_length\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Model, tokenizer, label encoder, and config saved in 'model/' folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753ddede",
   "metadata": {},
   "source": [
    "# This the downloaded data for spam as emails,csv from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ===== LOAD CSV =====\n",
    "csv_path = \"emails.csv\"   # change if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns in your CSV\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "true_labels = df[\"spam\"].astype(int).tolist()   # 1 = spam, 0 = not spam\n",
    "\n",
    "# ===== PREPARE DATA =====\n",
    "X_test = classifier.prepare_data(texts, is_training=False)\n",
    "\n",
    "# ===== PREDICT =====\n",
    "y_pred_probs = classifier.model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# ===== MAP MODEL OUTPUT TO BINARY =====\n",
    "# Adjust this if your label_encoder mapping is different\n",
    "label_map = {\n",
    "    \"spam\": 1,\n",
    "    \"not_spam\": 0,\n",
    "    \"job_application\": 0,\n",
    "    \"interview_scheduling\": 0,\n",
    "    \"candidate_selection\": 0,\n",
    "    \"new_requisition\": 0\n",
    "}\n",
    "\n",
    "y_pred_binary = [\n",
    "    label_map[classifier.label_encoder.classes_[i]] for i in y_pred\n",
    "]\n",
    "\n",
    "# ===== METRICS =====\n",
    "total = len(true_labels)\n",
    "correct = sum(t == p for t, p in zip(true_labels, y_pred_binary))\n",
    "wrong = total - correct\n",
    "\n",
    "correct_pct = (correct / total) * 100\n",
    "wrong_pct = (wrong / total) * 100\n",
    "accuracy = accuracy_score(true_labels, y_pred_binary)\n",
    "\n",
    "# ===== OUTPUT =====\n",
    "print(\"üìä MODEL TEST RESULTS\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Total Samples        : {total}\")\n",
    "print(f\"Correct Predictions  : {correct} ({correct_pct:.2f}%)\")\n",
    "print(f\"Wrong Predictions    : {wrong} ({wrong_pct:.2f}%)\")\n",
    "print(f\"Overall Accuracy     : {accuracy:.4f}\")\n",
    "\n",
    "# ===== CLASSIFICATION REPORT =====\n",
    "print(\"\\nüìÑ Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    y_pred_binary,\n",
    "    target_names=[\"not_spam\", \"spam\"],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# ===== CONFUSION MATRIX =====\n",
    "cm = confusion_matrix(true_labels, y_pred_binary)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"not_spam\", \"spam\"],\n",
    "    yticklabels=[\"not_spam\", \"spam\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Spam Classification Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7e4cb",
   "metadata": {},
   "source": [
    "# changes Made by Ayush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57184c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Embedding, LSTM,\n",
    "    Bidirectional, GlobalAveragePooling1D, Input, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=8000, max_length=500, embedding_dim=128):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    # More comprehensive preprocessing\n",
    "    def preprocess_text(self, text):\n",
    "        text = str(text)[:5000] # Limit length to prevent memory issues\n",
    "        text = text.lower()\n",
    "        # Expand contractions (basic example, can be improved)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"n't\", \" not\", text)\n",
    "        text = re.sub(r\"'re\", \" are\", text)\n",
    "        text = re.sub(r\"'ve\", \" have\", text)\n",
    "        text = re.sub(r\"'ll\", \" will\", text)\n",
    "        text = re.sub(r\"'d\", \" would\", text)\n",
    "        text = re.sub(r\"'m\", \" am\", text)\n",
    "        # Remove special characters, keep essential ones like @, ., +, - for emails/URLs\n",
    "        text = re.sub(r'[^a-zA-Z0-9@._%+-]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove leading/trailing spaces\n",
    "        return text.strip()\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        texts = [self.preprocess_text(t) for t in texts]\n",
    "\n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "\n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "                print(f\"Number of classes: {self.num_classes}, Classes: {self.label_encoder.classes_}\")\n",
    "            else:\n",
    "                # Handle unknown labels during prediction if necessary\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer\n",
    "        inputs = Input(shape=(self.max_length,))\n",
    "\n",
    "        # Embedding layer\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=min(self.max_features, len(self.tokenizer.word_index) + 1),\n",
    "            output_dim=self.embedding_dim,\n",
    "            input_length=self.max_length,\n",
    "            # Add regularization to embedding layer\n",
    "            embeddings_regularizer=l2(1e-4)\n",
    "        )(inputs)\n",
    "\n",
    "        # Dropout on embeddings to prevent overfitting to specific word vectors\n",
    "        embedding_layer = Dropout(0.2)(embedding_layer)\n",
    "\n",
    "        # BiLSTM layer with return sequences for potential subsequent pooling/attention\n",
    "        lstm_out = Bidirectional(\n",
    "            LSTM(64, return_sequences=True, recurrent_dropout=0.2, recurrent_regularizer=l2(1e-4))\n",
    "        )(embedding_layer)\n",
    "\n",
    "        # Global Average Pooling (GAP) - Good for capturing overall meaning\n",
    "        gap = GlobalAveragePooling1D()(lstm_out)\n",
    "\n",
    "        # Dense layers with regularization and dropout\n",
    "        dense1 = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(gap)\n",
    "        dropout1 = Dropout(0.5)(dense1) # Higher dropout for dense layer\n",
    "\n",
    "        dense2 = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(dropout1)\n",
    "        dropout2 = Dropout(0.3)(dense2)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = Dense(self.num_classes, activation='softmax')(dropout2)\n",
    "\n",
    "        self.model = Model(inputs, outputs)\n",
    "        # Using a lower learning rate initially\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=32): # Increased epochs\n",
    "        X_tr, y_tr = self.prepare_data(X_train, y_train, is_training=True)\n",
    "        X_v, y_v = self.prepare_data(X_val, y_val, is_training=False)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        # Compute class weights (still useful)\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_tr),\n",
    "            y=y_tr\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        print(f\"Class Weights: {class_weight_dict}\")\n",
    "\n",
    "        # Callbacks\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=6, # Increased patience\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5, # Reduce LR by half\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        history = self.model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_v, y_v),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop, reduce_lr], # Added ReduceLROnPlateau\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        preds = np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "        print(\"\\n--- Detailed Classification Report ---\")\n",
    "        print(classification_report(\n",
    "            y, preds,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            digits=4\n",
    "        ))\n",
    "\n",
    "        print(\"\\n--- Per-Class Precision, Recall, F1-Score ---\")\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y, preds, average=None, labels=np.unique(y))\n",
    "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
    "            print(f\"{class_name}: P={precision[i]:.4f}, R={recall[i]:.4f}, F1={f1[i]:.4f}, Support={support[i]}\")\n",
    "\n",
    "        cm = confusion_matrix(y, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "\n",
    "    def predict_probabilities(self, texts):\n",
    "        X = self.prepare_data(texts, is_training=False)\n",
    "        preds = self.model.predict(X)\n",
    "\n",
    "        for i, p in enumerate(preds):\n",
    "            print(f\"\\n--- Text {i+1}: {texts[i][:100]}... ---\") # Show more of the text\n",
    "            sorted_indices = np.argsort(p)[::-1]\n",
    "            for idx in sorted_indices[:2]: # Show top 2 predictions\n",
    "                class_name = self.label_encoder.classes_[idx]\n",
    "                prob = p[idx]\n",
    "                print(f\"  {class_name}: {prob*100:.2f}%\")\n",
    "            # Add a threshold check if needed\n",
    "            max_prob = np.max(p)\n",
    "            if max_prob < 0.7: # Example threshold\n",
    "                print(f\"  [Low Confidence: Max Prob = {max_prob*100:.2f}%]\")\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "df = pd.read_csv('final_training_data1.csv')\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "df = df.dropna(subset=['label', 'text'])\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# --- Investigate Class Distribution BEFORE balancing ---\n",
    "print(\"--- Original Class Distribution ---\")\n",
    "original_counts = df['label'].value_counts()\n",
    "print(original_counts)\n",
    "print(f\"Total samples before balancing: {len(df)}\")\n",
    "\n",
    "# Balance the dataset by taking up to 450 samples per class (or less if fewer exist)\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(min(len(x), 450), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Balanced Class Distribution ---\")\n",
    "balanced_counts = df_balanced['label'].value_counts()\n",
    "print(balanced_counts)\n",
    "print(f\"Total samples after balancing: {len(df_balanced)}\")\n",
    "\n",
    "texts = df_balanced['text'].tolist()\n",
    "labels = df_balanced['label'].tolist()\n",
    "\n",
    "# --- Split Data ---\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    texts, labels, test_size=0.3, stratify=labels, random_state=42 # Increased test size slightly\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42 # ~0.2 of total\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# --- Initialize and Train Model ---\n",
    "classifier = ImprovedATSEmailClassifier(max_features=8000, max_length=500, embedding_dim=128)\n",
    "history = classifier.train(X_train, y_train, X_val, y_val, epochs=20, batch_size=32)\n",
    "\n",
    "# --- Evaluate on Test Set ---\n",
    "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
    "classifier.evaluate(X_test, y_test)\n",
    "\n",
    "# --- Plot Training History ---\n",
    "if history:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Example Prediction on New Data ---\n",
    "# Replace these with your truly new data\n",
    "new_texts = [\n",
    "    \"Dear Hiring Manager, I am writing to apply for the Data Scientist position...\",\n",
    "    \"Subject: New Role: Content Writer (Finance)...\",\n",
    "    \"URGENT!! You have been selected to receive a Free Trip!...\",\n",
    "    # Add more examples from your new data\n",
    "]\n",
    "\n",
    "print(\"\\n--- Predictions on New Texts ---\")\n",
    "classifier.predict_probabilities(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "spam_emails= pd.read_csv('emails.csv')\n",
    "print(spam_emails.describe())\n",
    "spam_emails.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7197068",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = [\n",
    "    \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "    \"Buy now! Free gift offer limited time\"\n",
    "]\n",
    "classifier.predict_probabilities(test_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = \" unsubscribe offer offer buy this car get a gift free.\"\n",
    "print(f\"Predicted Category: {classifier.predict_probabilities(test_emails)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" i want to  apply offer offer buy this car get a gift free.\"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179125d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to your ImprovedATSEmailClassifier class\n",
    "def predict_probabilities(self, texts):\n",
    "    X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "    preds = self.model.predict(X)\n",
    "    for i, p in enumerate(preds):\n",
    "        print(f\"Text: {texts[i][:50]}...\")\n",
    "        for j, class_name in enumerate(self.label_encoder.classes_):\n",
    "            print(f\" - {class_name}: {p[j]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19623f2c",
   "metadata": {},
   "source": [
    "# checking the working of model work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c912b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# A list of \"tricky\" emails covering all 5 labels\n",
    "test_data = [\n",
    "    # Testing SPAM (with job keywords)\n",
    "    \"I want to apply offer offer buy this car get a gift free.\",\n",
    "    \"URGENT: Your job application requires a $500 processing fee. Click here to win!\",\n",
    "    \n",
    "    # Testing JOB_APPLICATION (with unusual phrasing)\n",
    "    \"Please find my resume attached for the open position, I am very interested.\",\n",
    "    \"Submission of candidate profile for the engineering role.\",\n",
    "    \n",
    "    # Testing CANDIDATE_SELECTION (Internal HR talk)\n",
    "    \"The hiring committee has finalized the selection for the Senior Dev role.\",\n",
    "    \"We have chosen a candidate from the final shortlist, please inform the team.\",\n",
    "    \n",
    "    # Testing INTERVIEW_SCHEDULING (Time/Date focus)\n",
    "    \"Are you available for a Zoom call this Thursday at 10 AM?\",\n",
    "    \"Confirming the technical interview for next Monday.\",\n",
    "    \n",
    "    # Testing NEW_REQUISITION (Managerial/Internal)\n",
    "    \"Need approval for a new requisition for the Sales Department.\",\n",
    "    \"Budget approved for a new headcount: please open a requisition for a Designer.\"\n",
    "]\n",
    "\n",
    "# Randomize the order\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(\"--- Multi-Label Stress Test ---\")\n",
    "for email in test_data:\n",
    "    prediction = classifier.predict([email])[0]\n",
    "    print(f\"Test Text: \\\"{email[:60]}...\\\"\")\n",
    "    print(f\"Predicted Category: {prediction}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40872d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# A list of emails with their \"True Label\" for verification\n",
    "test_cases = [\n",
    "    {\n",
    "        \"email\": \"i want to apply offer offer buy this car get a gift free.\",\n",
    "        \"true_label\": \"spam\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "        \"true_label\": \"job_application\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Are you available for a Zoom interview this Wednesday at 3 PM?\",\n",
    "        \"true_label\": \"interview_scheduling\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"The hiring committee has finalized the selection for the Senior Lead role.\",\n",
    "        \"true_label\": \"candidate_selection\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"We need to open a new requisition for the Marketing Manager headcount.\",\n",
    "        \"true_label\": \"new_requisition\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Claim your inheritance! We just need your bank details to send the funds.\",\n",
    "        \"true_label\": \"spam\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Randomize the test order\n",
    "random.shuffle(test_cases)\n",
    "\n",
    "print(f\"{'TRUE LABEL':<25} | {'PREDICTED':<25} | {'STATUS'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for case in test_cases:\n",
    "    text = case[\"email\"]\n",
    "    true_lbl = case[\"true_label\"]\n",
    "    \n",
    "    # Get prediction from your trained classifier\n",
    "    predicted_lbl = classifier.predict([text])[0]\n",
    "    \n",
    "    # Check if the model was correct\n",
    "    status = \"‚úÖ CORRECT\" if predicted_lbl == true_lbl else \"‚ùå WRONG\"\n",
    "    \n",
    "    print(f\"{true_lbl:<25} | {predicted_lbl:<25} | {status}\")\n",
    "    if status == \"‚ùå WRONG\":\n",
    "        print(f\"   ‚îî‚îÄ Text: \\\"{text}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" for the offer offer buy this car get a gift free.test_email \"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")  \n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab72771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh test list\n",
    "test_emails = [\n",
    "    \"I am applying for the data analyst position. Attached is my resume.\",\n",
    "    \"WINNER! You have a gift waiting. Click here to claim your car offer now!\"\n",
    "]\n",
    "\n",
    "# Use the predict method\n",
    "# This calls prepare_data(is_training=False) internally\n",
    "results = classifier.predict(test_emails)\n",
    "\n",
    "for email, category in zip(test_emails, results):\n",
    "    print(f\"Text: {email[:50]}...\")\n",
    "    print(f\"RESULT: {category}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 1. Save the Keras Model (The neural network weights)\n",
    "# # Using .keras is the modern standard for TensorFlow/Keras\n",
    "# classifier.model.save('improved_ats_model.keras')\n",
    "\n",
    "# # 2. Save the Tokenizer (The dictionary mapping words to numbers)\n",
    "# with open('tokenizer.pkl', 'wb') as handle:\n",
    "#     pickle.dump(classifier.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # 3. Save the Label Encoder (The mapping of numbers back to \"Spam\", \"Job\", etc.)\n",
    "# with open('label_encoder.pkl', 'wb') as handle:\n",
    "#     pickle.dump(classifier.label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# print(\"All components (Model, Tokenizer, Label Encoder) saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f96d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample emails from each category\n",
    "unique_categories = df['category'].unique()\n",
    "print(\"Testing predictions for sample emails from each category:\")\n",
    "for cat in unique_categories:\n",
    "    sample_email = df[df['category'] == cat]['email_text'].sample(1).values[0][:200]  # Take first 200 chars for brevity\n",
    "    predicted = classifier.predict([sample_email])[0]\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(f\"Sample Email: {sample_email}...\")\n",
    "    print(f\"Predicted: {predicted}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # from pydantic_settings import BaseSettings\n",
    "# from ydata_profiling import ProfileReport  \n",
    "# df = pd.read_csv('final_training_data.csv')\n",
    "# profile = ProfileReport(df, title=\"Pandas Profiling Report\")    \n",
    "# profile.to_file(\"final_training_data_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275884f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_training_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7a49e",
   "metadata": {},
   "source": [
    "## added L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2  # <--- NEW: Import for regularization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=10000, max_length=500):\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean text AND remove the 'cheat words' used to label the data.\n",
    "        This forces the model to learn from context, not just keywords.\n",
    "        \"\"\"\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # --- NEW: THE CHEAT SHEET SCRUBBER ---\n",
    "        # These are the exact words used to create the labels. \n",
    "        # We replace them with [MASK] so the model has to look at the surrounding words.\n",
    "        cheat_words = [\n",
    "            'resume', 'cv', 'interview', 'schedule', 'availability', \n",
    "            'requisition', 'headcount', 'spam', 'unsubscribe', 'click here'\n",
    "        ]\n",
    "        for word in cheat_words:\n",
    "            text = text.replace(word, '') \n",
    "        # -------------------------------------\n",
    "\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        return text\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Added L2 Regularization and reduced complexity.\n",
    "        This penalizes the model for being too confident about simple patterns.\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            # Reduced embedding size to 64 to create a \"bottleneck\"\n",
    "            Embedding(self.max_features, 64, input_length=self.max_length),\n",
    "            \n",
    "            # Added L2 Regularization (kernel_regularizer)\n",
    "            Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01))),\n",
    "            GlobalMaxPooling1D(),\n",
    "            \n",
    "            # Added L2 to Dense layers too\n",
    "            Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dropout(0.6), # Increased Dropout to 60%\n",
    "            \n",
    "            Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dropout(0.6),\n",
    "            \n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, texts, labels, validation_split=0.2, epochs=15, batch_size=32):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=True)\n",
    "        self.build_model()\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=3, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X, y,\n",
    "            validation_split=validation_split,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, texts):\n",
    "        X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "        \n",
    "        # \n",
    "        cm = confusion_matrix(y, predicted_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Confusion Matrix (Regularized Model)')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "\n",
    "# --- RUNNING THE CODE ---\n",
    "# --- CORRECTED DATA LOADING SECTION ---\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv('final_training_data.csv')\n",
    "\n",
    "# 2. Rename columns based on your file structure (Label is 1st, Text is 2nd)\n",
    "# Your snippet shows: column 0 = label, column 1 = text\n",
    "df.columns = ['label', 'text'] \n",
    "\n",
    "# 3. Verify it looks right before continuing\n",
    "print(\"--- Data Preview ---\")\n",
    "print(df.head(2))\n",
    "\n",
    "# 4. Filter and Prepare\n",
    "df = df.dropna(subset=['text'])\n",
    "df = df[df['text'].str.len() > 20] # Remove empty/short rows\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# 5. Split and Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training on {len(X_train)} emails, Testing on {len(X_test)} emails.\")\n",
    "\n",
    "classifier = ImprovedATSEmailClassifier()\n",
    "# Train for 15 epochs since we made the task harder with regularization\n",
    "history = classifier.train(X_train, y_train, epochs=15) \n",
    "\n",
    "# Evaluate\n",
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53642777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email = \" for the offer offer buy this car get a gift free.test_email \"\n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\")  \n",
    "print(f\"Predicted Category: {classifier.predict([test_email])[0]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7e1be",
   "metadata": {},
   "source": [
    "# Lightweight GRU architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2415f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class ImprovedATSEmailClassifier:\n",
    "    def __init__(self, max_features=3000, max_length=300):\n",
    "        # Reduced max_features and length to prevent overfitting on small data\n",
    "        self.max_features = max_features\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean text: lowercase, remove punctuation, stop words.\"\"\"\n",
    "        text = str(text).lower()\n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        return text\n",
    "\n",
    "    def prepare_data(self, texts, labels=None, is_training=True):\n",
    "        processed_texts = [self.preprocess_text(t) for t in texts]\n",
    "        \n",
    "        if is_training:\n",
    "            self.tokenizer.fit_on_texts(processed_texts)\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(processed_texts)\n",
    "        X = pad_sequences(sequences, maxlen=self.max_length)\n",
    "        \n",
    "        if labels is not None:\n",
    "            if is_training:\n",
    "                y = self.label_encoder.fit_transform(labels)\n",
    "                self.num_classes = len(np.unique(y))\n",
    "            else:\n",
    "                y = self.label_encoder.transform(labels)\n",
    "            return X, y\n",
    "        return X\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Lightweight GRU model:\n",
    "        - Lower embedding dim (64)\n",
    "        - SpatialDropout1D to force context learning\n",
    "        - Single GRU layer to reduce parameter count\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            Embedding(self.max_features, 64, input_length=self.max_length),\n",
    "            SpatialDropout1D(0.3), \n",
    "            GRU(64, return_sequences=True),\n",
    "            GlobalMaxPooling1D(), # Picks the most important signals from the GRU\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5), \n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, texts, labels, validation_split=0.2, epochs=10, batch_size=32):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=True)\n",
    "        self.build_model()\n",
    "        \n",
    "        # Handle class imbalance\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        # Paitence reduced to 2 for faster cutoff if overfitting starts\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=2, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X, y,\n",
    "            validation_split=validation_split,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, texts):\n",
    "        X = self.prepare_data(texts, labels=None, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        return self.label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X, y = self.prepare_data(texts, labels, is_training=False)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        print(classification_report(y, predicted_classes, target_names=self.label_encoder.classes_))\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('final_training_data.csv')\n",
    "    # Basic data cleaning\n",
    "    df.columns = ['category', 'email_text']\n",
    "    df = df.dropna(subset=['email_text', 'category'])\n",
    "    \n",
    "    texts = df['email_text'].tolist()\n",
    "    labels = df['category'].tolist()\n",
    "\n",
    "    # Stratified split ensures classes are balanced in both train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Initialize and Train\n",
    "    classifier = ImprovedATSEmailClassifier(max_features=3000, max_length=300)\n",
    "    history = classifier.train(X_train, y_train, epochs=10)\n",
    "\n",
    "    # Evaluate on unseen data\n",
    "    classifier.evaluate(X_test, y_test)\n",
    "\n",
    "    # Visualizing the Training Process\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss (Look for Divergence)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Test Predictions\n",
    "    sample_emails = [\n",
    "        \"I am interested in the Software Engineer role. Please see my resume.\",\n",
    "        \"URGENT: Win a free car now! Click this link to claim your offer prize!\"\n",
    "    ]\n",
    "    \n",
    "    for email in sample_emails:\n",
    "        pred = classifier.predict([email])[0]\n",
    "        print(f\"Email: {email[:50]}... \\nPredicted: {pred}\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'final_training_data.csv' not found. Please ensure the file is in the same directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample emails from each category\n",
    "unique_categories = df['label'].unique()\n",
    "print(\"Testing predictions for sample emails from each category:\")\n",
    "for cat in unique_categories:\n",
    "    sample_email = df[df['label'] == cat]['text'].sample(1).values[0][:200]  # Take first 200 chars for brevity\n",
    "    predicted = classifier.predict([sample_email])[0]\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(f\"Sample Email: {sample_email}...\")\n",
    "    print(f\"Predicted: {predicted}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78dbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66d54e2",
   "metadata": {},
   "source": [
    "# Using Bert \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch tf-keras accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f6d33",
   "metadata": {},
   "source": [
    "# STEP 0: Install Requirements (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca141bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow transformers scikit-learn pandas matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d0d88",
   "metadata": {},
   "source": [
    "# STEP 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee826691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8eead",
   "metadata": {},
   "source": [
    "# STEP 2: Load & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69baa701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_training_data1.csv\")\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df = df.dropna(subset=[\"label\", \"text\"])\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Original Class Distribution:\")\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d874fd",
   "metadata": {},
   "source": [
    "# STEP 3: Balance Dataset (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72261c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df.groupby(\"label\").apply(\n",
    "    lambda x: x.sample(min(len(x), 450), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Class Distribution:\")\n",
    "print(df_balanced[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef840e",
   "metadata": {},
   "source": [
    "# STEP 4: Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155095cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_balanced[\"label_encoded\"] = label_encoder.fit_transform(df_balanced[\"label\"])\n",
    "\n",
    "num_classes = df_balanced[\"label_encoded\"].nunique()\n",
    "print(\"\\nClasses:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87089632",
   "metadata": {},
   "source": [
    "# STEP 5: Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df_balanced[\"text\"],\n",
    "    df_balanced[\"label_encoded\"],\n",
    "    test_size=0.3,\n",
    "    stratify=df_balanced[\"label_encoded\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.33,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8a6f9",
   "metadata": {},
   "source": [
    "# STEP 6: Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5d9c8",
   "metadata": {},
   "source": [
    "# STEP 7: Tokenization Function (BERT Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=256):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = bert_encode(X_train, tokenizer)\n",
    "val_enc   = bert_encode(X_val, tokenizer)\n",
    "test_enc  = bert_encode(X_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495fc35",
   "metadata": {},
   "source": [
    "# STEP 8: Compute Class Weights (IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb529a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a965e3",
   "metadata": {},
   "source": [
    "# STEP 9: Load BERT Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_classes,\n",
    "    from_pt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6b462",
   "metadata": {},
   "source": [
    "# STEP 10: Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4101b",
   "metadata": {},
   "source": [
    "# STEP 11: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a061ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dict(train_enc),\n",
    "    y_train,\n",
    "    validation_data=(dict(val_enc), y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    class_weight=class_weight_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021279e",
   "metadata": {},
   "source": [
    "# STEP 12: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(dict(test_enc))\n",
    "y_pred = np.argmax(test_preds.logits, axis=1)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf6049",
   "metadata": {},
   "source": [
    "# STEP 13: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b975b1",
   "metadata": {},
   "source": [
    "# STEP 14: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f635027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958e0c7",
   "metadata": {},
   "source": [
    "# STEP 15: Predict on New Emails (With Confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_email(text):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    logits = model(enc).logits\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    idx = tf.argmax(probs, axis=1).numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"predicted_class\": label_encoder.classes_[idx],\n",
    "        \"confidence\": float(probs[0][idx])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9745db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_email' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m sample_email = \u001b[33m\"\"\"\u001b[39m\u001b[33mSubject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33mDear Customer,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33mSecurity Team\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33mCustomer Support Department\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_email\u001b[49m(sample_email))\n",
      "\u001b[31mNameError\u001b[39m: name 'predict_email' is not defined"
     ]
    }
   ],
   "source": [
    "sample_email = \"\"\"Subject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\n",
    "\n",
    "Dear Customer,\n",
    "\n",
    "We detected suspicious activity on your account. For your safety, we have temporarily limited access to your account.\n",
    "\n",
    "To restore full access, please verify your details immediately by clicking the secure link below:\n",
    "\n",
    "üëâ Verify Your Account Now\n",
    "\n",
    "Failure to verify within 24 hours may result in permanent suspension of your account.\n",
    "\n",
    "Thank you for your prompt attention.\n",
    "\n",
    "Sincerely,\n",
    "Security Team\n",
    "Customer Support Department\"\"\"\n",
    "print(predict_email(sample_email))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841cb03",
   "metadata": {},
   "source": [
    "# STEP 16: Save Model & Tokenizer (IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100599ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bert_ats_model\")\n",
    "tokenizer.save_pretrained(\"bert_ats_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b23d3",
   "metadata": {},
   "source": [
    "# Complete code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d69a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.13.0\n",
      "Uninstalling keras-3.13.0:\n",
      "  Successfully uninstalled keras-3.13.0\n",
      "Found existing installation: transformers 4.57.3\n",
      "Uninstalling transformers-4.57.3:\n",
      "  Successfully uninstalled transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.32.5)\n",
      "Requirement already satisfied: setuptools in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.16.2)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.2->tensorflow==2.16.2)\n",
      "  Using cached keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\talentprism\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\talentprism\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.1.4)\n",
      "Requirement already satisfied: filelock in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\talentprism\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\talentprism\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\talentprism\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.45.1)\n",
      "Requirement already satisfied: rich in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (14.2.0)\n",
      "Requirement already satisfied: namex in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.0)\n",
      "Requirement already satisfied: optree in e:\\talentprism\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.18.0)\n",
      "Requirement already satisfied: colorama in e:\\talentprism\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in e:\\talentprism\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\talentprism\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\talentprism\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\talentprism\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.2)\n",
      "Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: keras, transformers, tensorflow\n",
      "\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ---------------------------------------- 0/3 [keras]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ------------- -------------------------- 1/3 [transformers]\n",
      "   ---------------------------------------- 3/3 [tensorflow]\n",
      "\n",
      "Successfully installed keras-3.13.0 tensorflow-2.16.2 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.20.1 requires tensorflow<2.21,>=2.20, but you have tensorflow 2.16.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall tensorflow keras transformers -y\n",
    "%pip install tensorflow==2.16.2 transformers\n",
    "\n",
    "# %pip install tensorflow==2.12.1 keras==2.12.0 transformers==4.37.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a0b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "label\n",
      "job_application          618\n",
      "candidate_application    596\n",
      "spam                     523\n",
      "new_requisition          515\n",
      "interview_scheduling     510\n",
      "candidate_selection      454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced Class Distribution:\n",
      "label\n",
      "candidate_application    450\n",
      "candidate_selection      450\n",
      "interview_scheduling     450\n",
      "job_application          450\n",
      "new_requisition          450\n",
      "spam                     450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: ['candidate_application' 'candidate_selection' 'interview_scheduling'\n",
      " 'job_application' 'new_requisition' 'spam']\n",
      "\n",
      "Train: 1890, Val: 542, Test: 268\n",
      "\n",
      "Class Weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 2240s 18s/step - loss: 0.6786 - accuracy: 0.8788 - val_loss: 0.1042 - val_accuracy: 0.9982 - lr: 2.0000e-05\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 2127s 18s/step - loss: 0.0627 - accuracy: 0.9984 - val_loss: 0.0312 - val_accuracy: 0.9982 - lr: 2.0000e-05\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 1677s 14s/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 1903s 16s/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 1817s 15s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "9/9 [==============================] - 70s 7s/step\n",
      "\n",
      "--- Classification Report ---\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "candidate_application     1.0000    1.0000    1.0000        44\n",
      "  candidate_selection     1.0000    1.0000    1.0000        44\n",
      " interview_scheduling     1.0000    1.0000    1.0000        45\n",
      "      job_application     1.0000    1.0000    1.0000        45\n",
      "      new_requisition     1.0000    1.0000    1.0000        45\n",
      "                 spam     1.0000    1.0000    1.0000        45\n",
      "\n",
      "             accuracy                         1.0000       268\n",
      "            macro avg     1.0000    1.0000    1.0000       268\n",
      "         weighted avg     1.0000    1.0000    1.0000       268\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'job_application', 'confidence': 0.978675365447998}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn while saving (showing 5 of 422). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_ats_model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_ats_model2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert_ats_tokenizer2\\\\tokenizer_config.json',\n",
       " 'bert_ats_tokenizer2\\\\special_tokens_map.json',\n",
       " 'bert_ats_tokenizer2\\\\vocab.txt',\n",
       " 'bert_ats_tokenizer2\\\\added_tokens.json',\n",
       " 'bert_ats_tokenizer2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================== COMPLETE BERT-BASED ATS EMAIL CLASSIFIER =====================\n",
    "# Copy‚ÄìPaste Ready | Includes EarlyStopping, ReduceLROnPlateau, Class Weights,\n",
    "# Dataset Balancing, Stratified Splits, Overfitting Controls, and Safe BERT Loading\n",
    "# ==================================================================================\n",
    "\n",
    "# ---------- STEP 0: IMPORT LIBRARIES ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# ---------- STEP 1: LOAD & CLEAN DATA ----------\n",
    "df = pd.read_csv(\"E:\\Synthetic-Email-Generation-tool-main\\data\\combined_with_candidate_application.csv\")\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df = df.dropna(subset=[\"label\", \"text\"])\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Original Class Distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "\n",
    "# ---------- STEP 2: BALANCE DATASET (ANTI-IMBALANCE) ----------\n",
    "df_balanced = df.groupby(\"label\").apply(\n",
    "    lambda x: x.sample(min(len(x), 450), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Class Distribution:\")\n",
    "print(df_balanced[\"label\"].value_counts())\n",
    "\n",
    "\n",
    "# ---------- STEP 3: LABEL ENCODING ----------\n",
    "label_encoder = LabelEncoder()\n",
    "df_balanced[\"label_encoded\"] = label_encoder.fit_transform(df_balanced[\"label\"])\n",
    "\n",
    "num_classes = df_balanced[\"label_encoded\"].nunique()\n",
    "print(\"\\nClasses:\", label_encoder.classes_)\n",
    "\n",
    "\n",
    "# ---------- STEP 4: TRAIN / VAL / TEST SPLIT (STRATIFIED) ----------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df_balanced[\"text\"],\n",
    "    df_balanced[\"label_encoded\"],\n",
    "    test_size=0.3,\n",
    "    stratify=df_balanced[\"label_encoded\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.33,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "\n",
    "# ---------- STEP 5: LOAD BERT TOKENIZER ----------\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# ---------- STEP 6: TOKENIZATION FUNCTION ----------\n",
    "def bert_encode(texts, tokenizer, max_len=256):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "train_enc = bert_encode(X_train, tokenizer)\n",
    "val_enc   = bert_encode(X_val, tokenizer)\n",
    "test_enc  = bert_encode(X_test, tokenizer)\n",
    "\n",
    "\n",
    "# ---------- STEP 7: CLASS WEIGHTS (ANTI-IMBALANCE) ----------\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Weights:\", class_weight_dict)\n",
    "\n",
    "\n",
    "# ---------- STEP 8: LOAD BERT MODEL (SAFE LOAD FIX) ----------\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_classes,\n",
    "    from_pt=True  # fixes safetensors / safe_open error\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 9: COMPILE MODEL (LOW LR = LESS OVERFITTING) ----------\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 10: CALLBACKS ----------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 11: TRAIN MODEL ----------\n",
    "history = model.fit(\n",
    "    dict(train_enc),\n",
    "    y_train,\n",
    "    validation_data=(dict(val_enc), y_val),\n",
    "    epochs=5,          # BERT converges fast\n",
    "    batch_size=16,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- STEP 12: EVALUATE ON TEST SET ----------\n",
    "test_preds = model.predict(dict(test_enc))\n",
    "y_pred = np.argmax(test_preds.logits, axis=1)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "\n",
    "# ---------- STEP 13: CONFUSION MATRIX ----------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- STEP 14: TRAINING CURVES ----------\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- STEP 15: CONFIDENCE-AWARE PREDICTION ----------\n",
    "def predict_email(text, threshold=0.7):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    logits = model(enc).logits\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    idx = tf.argmax(probs, axis=1).numpy()[0]\n",
    "    confidence = float(probs[0][idx])\n",
    "\n",
    "    result = {\n",
    "        \"predicted_class\": label_encoder.classes_[idx],\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "    if confidence < threshold:\n",
    "        result[\"warning\"] = \"Low confidence prediction\"\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------- STEP 16: SAMPLE PREDICTION ----------\n",
    "print(predict_email(\"Dear HR, I am applying for the Data Scientist position.\"))\n",
    "\n",
    "\n",
    "# ---------- STEP 17: SAVE MODEL & TOKENIZER ----------\n",
    "model.save(\"bert_ats_model2\")\n",
    "tokenizer.save_pretrained(\"bert_ats_tokenizer2\")\n",
    "\n",
    "# ===================== END OF COMPLETE CODE =====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5598fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'spam', 'confidence': 0.9879586696624756}\n"
     ]
    }
   ],
   "source": [
    "sample_email = \"\"\"Subject: üö® Urgent! Your Account Has Been Compromised ‚Äì Verify Now\n",
    "\n",
    "Dear Customer,\n",
    "\n",
    "We detected suspicious activity on your account. For your safety, we have temporarily limited access to your account.\n",
    "\n",
    "To restore full access, please verify your details immediately by clicking the secure link below:\n",
    "\n",
    "üëâ Verify Your Account Now\n",
    "\n",
    "Failure to verify within 24 hours may result in permanent suspension of your account.\n",
    "\n",
    "Thank you for your prompt attention.\n",
    "\n",
    "Sincerely,\n",
    "Security Team\n",
    "Customer Support Department\"\"\"\n",
    "print(predict_email(sample_email))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab82b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'job_application', 'confidence': 0.978675365447998}\n"
     ]
    }
   ],
   "source": [
    "print(predict_email(\"Dear HR, I am applying for the Data Scientist position.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c168413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CATEGORY: JOB_APPLICATION ================\n",
      "\n",
      "Email: Dear Hiring Manager,\n",
      "        I am writing to apply for the Data Scientist position at your organization.\n",
      "        I have attached my resume for your review and believe my skills in Python,\n",
      "        machine learning, and data analysis align well with the role requirements.\n",
      "        I look forward to hearing from you regarding the next steps.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9891462326049805}\n",
      "\n",
      "Email: Hello Team,\n",
      "        I would like to formally apply for the Software Engineer role advertised on your careers page.\n",
      "        With hands-on experience in backend development and problem-solving,\n",
      "        I am confident I can contribute effectively to your team.\n",
      "        Please find my resume attached for further details.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9891452789306641}\n",
      "\n",
      "Email: Respected Sir/Madam,\n",
      "        I am interested in the Machine Learning Engineer position currently open at your company.\n",
      "        My academic background and project experience closely match the job description.\n",
      "        Kindly consider my application for further evaluation.\n",
      "Prediction: {'predicted_class': 'job_application', 'confidence': 0.9887696504592896}\n",
      "\n",
      "================ CATEGORY: CANDIDATE_APPLICATION ================\n",
      "\n",
      "Email: Thank you for applying for the position with our organization.\n",
      "        We have successfully received your application and resume.\n",
      "        Our hiring team is currently reviewing all applications,\n",
      "        and we will contact you regarding the next steps within 3‚Äì5 business days.\n",
      "Prediction: {'predicted_class': 'candidate_application', 'confidence': 0.9849308729171753}\n",
      "\n",
      "Email: This email is to confirm that your job application has been received.\n",
      "        Our recruitment team will carefully review your profile based on the role requirements.\n",
      "        If shortlisted, you will be contacted for the next stage of the hiring process.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.8134803771972656}\n",
      "\n",
      "Email: We appreciate your interest in joining our company.\n",
      "        Your application has been submitted successfully and is now under review.\n",
      "        Due to the high volume of applications, this process may take some time.\n",
      "        Thank you for your patience.\n",
      "Prediction: {'predicted_class': 'candidate_application', 'confidence': 0.9842993021011353}\n",
      "\n",
      "================ CATEGORY: INTERVIEW_SCHEDULING ================\n",
      "\n",
      "Email: Dear Candidate,\n",
      "        We are pleased to inform you that you have been shortlisted for the next round.\n",
      "        Your technical interview has been scheduled for Monday at 11:00 AM via video call.\n",
      "        Please confirm your availability or let us know if rescheduling is required.\n",
      "Prediction: {'predicted_class': 'interview_scheduling', 'confidence': 0.9919489622116089}\n",
      "\n",
      "Email: Congratulations on moving forward in the selection process.\n",
      "        We would like to schedule your interview with our technical panel this week.\n",
      "        Kindly share your availability for the next three working days so we can proceed.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.9113023281097412}\n",
      "\n",
      "Email: This is regarding your application for the mentioned position.\n",
      "        We would like to arrange an interview to discuss your profile in detail.\n",
      "        Please reply to this email with your preferred time slot.\n",
      "Prediction: {'predicted_class': 'interview_scheduling', 'confidence': 0.9071378111839294}\n",
      "\n",
      "================ CATEGORY: CANDIDATE_SELECTION ================\n",
      "\n",
      "Email: Congratulations!\n",
      "        We are delighted to inform you that you have been selected for the Data Analyst role.\n",
      "        You have successfully cleared all interview rounds.\n",
      "        Our HR team will reach out to you shortly with the offer letter and joining details.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.9739784002304077}\n",
      "\n",
      "Email: We are pleased to confirm your selection for the advertised position.\n",
      "        Your performance throughout the interview process was impressive.\n",
      "        Further documentation and onboarding information will be shared soon.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.9748293161392212}\n",
      "\n",
      "Email: Thank you for participating in our interview process.\n",
      "        We are happy to inform you that you have been shortlisted and selected.\n",
      "        Please keep an eye on your inbox for the next steps from our HR department.\n",
      "Prediction: {'predicted_class': 'candidate_selection', 'confidence': 0.915981113910675}\n",
      "\n",
      "================ CATEGORY: SPAM ================\n",
      "\n",
      "Email: URGENT!!!\n",
      "        Congratulations! You have been selected as the lucky winner of a brand-new iPhone.\n",
      "        Click the link below to claim your prize before the offer expires.\n",
      "        Act fast to avoid missing out on this limited-time opportunity!\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9934543371200562}\n",
      "\n",
      "Email: You are a lucky user!\n",
      "        Earn up to ‚Çπ50,000 per month working from home with zero investment.\n",
      "        No experience required. Click now to register and start earning today!\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9889350533485413}\n",
      "\n",
      "Email: FINAL NOTICE!!!\n",
      "        Your account has been selected for a cash reward.\n",
      "        Verify your details immediately to receive your prize.\n",
      "        Failure to respond may result in forfeiture of the reward.\n",
      "Prediction: {'predicted_class': 'spam', 'confidence': 0.9908561706542969}\n"
     ]
    }
   ],
   "source": [
    "# ---------------- SAMPLE EMAILS FOR EACH CATEGORY ----------------\n",
    "\n",
    "sample_emails = {\n",
    "\n",
    "    \"job_application\": [\n",
    "        \"\"\"Dear Hiring Manager,\n",
    "        I am writing to apply for the Data Scientist position at your organization.\n",
    "        I have attached my resume for your review and believe my skills in Python,\n",
    "        machine learning, and data analysis align well with the role requirements.\n",
    "        I look forward to hearing from you regarding the next steps.\"\"\",\n",
    "\n",
    "        \"\"\"Hello Team,\n",
    "        I would like to formally apply for the Software Engineer role advertised on your careers page.\n",
    "        With hands-on experience in backend development and problem-solving,\n",
    "        I am confident I can contribute effectively to your team.\n",
    "        Please find my resume attached for further details.\"\"\",\n",
    "\n",
    "        \"\"\"Respected Sir/Madam,\n",
    "        I am interested in the Machine Learning Engineer position currently open at your company.\n",
    "        My academic background and project experience closely match the job description.\n",
    "        Kindly consider my application for further evaluation.\"\"\"\n",
    "    ],\n",
    "\n",
    "    \"candidate_application\": [\n",
    "        \"\"\"Thank you for applying for the position with our organization.\n",
    "        We have successfully received your application and resume.\n",
    "        Our hiring team is currently reviewing all applications,\n",
    "        and we will contact you regarding the next steps within 3‚Äì5 business days.\"\"\",\n",
    "\n",
    "        \"\"\"This email is to confirm that your job application has been received.\n",
    "        Our recruitment team will carefully review your profile based on the role requirements.\n",
    "        If shortlisted, you will be contacted for the next stage of the hiring process.\"\"\",\n",
    "\n",
    "        \"\"\"We appreciate your interest in joining our company.\n",
    "        Your application has been submitted successfully and is now under review.\n",
    "        Due to the high volume of applications, this process may take some time.\n",
    "        Thank you for your patience.\"\"\"\n",
    "    ],\n",
    "\n",
    "    \"interview_scheduling\": [\n",
    "        \"\"\"Dear Candidate,\n",
    "        We are pleased to inform you that you have been shortlisted for the next round.\n",
    "        Your technical interview has been scheduled for Monday at 11:00 AM via video call.\n",
    "        Please confirm your availability or let us know if rescheduling is required.\"\"\",\n",
    "\n",
    "        \"\"\"Congratulations on moving forward in the selection process.\n",
    "        We would like to schedule your interview with our technical panel this week.\n",
    "        Kindly share your availability for the next three working days so we can proceed.\"\"\",\n",
    "\n",
    "        \"\"\"This is regarding your application for the mentioned position.\n",
    "        We would like to arrange an interview to discuss your profile in detail.\n",
    "        Please reply to this email with your preferred time slot.\"\"\"\n",
    "    ],\n",
    "\n",
    "    \"candidate_selection\": [\n",
    "        \"\"\"Congratulations!\n",
    "        We are delighted to inform you that you have been selected for the Data Analyst role.\n",
    "        You have successfully cleared all interview rounds.\n",
    "        Our HR team will reach out to you shortly with the offer letter and joining details.\"\"\",\n",
    "\n",
    "        \"\"\"We are pleased to confirm your selection for the advertised position.\n",
    "        Your performance throughout the interview process was impressive.\n",
    "        Further documentation and onboarding information will be shared soon.\"\"\",\n",
    "\n",
    "        \"\"\"Thank you for participating in our interview process.\n",
    "        We are happy to inform you that you have been shortlisted and selected.\n",
    "        Please keep an eye on your inbox for the next steps from our HR department.\"\"\"\n",
    "    ],\n",
    "\n",
    "    \"spam\": [\n",
    "        \"\"\"URGENT!!!\n",
    "        Congratulations! You have been selected as the lucky winner of a brand-new iPhone.\n",
    "        Click the link below to claim your prize before the offer expires.\n",
    "        Act fast to avoid missing out on this limited-time opportunity!\"\"\",\n",
    "\n",
    "        \"\"\"You are a lucky user!\n",
    "        Earn up to ‚Çπ50,000 per month working from home with zero investment.\n",
    "        No experience required. Click now to register and start earning today!\"\"\",\n",
    "\n",
    "        \"\"\"FINAL NOTICE!!!\n",
    "        Your account has been selected for a cash reward.\n",
    "        Verify your details immediately to receive your prize.\n",
    "        Failure to respond may result in forfeiture of the reward.\"\"\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------- RUN PREDICTIONS ----------------\n",
    "\n",
    "for category, emails in sample_emails.items():\n",
    "    print(f\"\\n================ CATEGORY: {category.upper()} ================\")\n",
    "    \n",
    "    for email in emails:\n",
    "        result = predict_email(email)\n",
    "        print(f\"\\nEmail: {email}\")\n",
    "        print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b03ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# # Encode labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "# num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# # Split data\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "#     df['email_text'].tolist(), df['category_encoded'].tolist(), test_size=0.2, random_state=42, stratify=df['category_encoded']\n",
    "# )\n",
    "\n",
    "# # Custom Dataset class\n",
    "# class EmailDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.texts[idx]\n",
    "#         label = self.labels[idx]\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_len,\n",
    "#             return_token_type_ids=False,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             return_attention_mask=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'labels': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# # Load BERT tokenizer and model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# # Create datasets\n",
    "# train_dataset = EmailDataset(train_texts, train_labels, tokenizer)\n",
    "# test_dataset = EmailDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# # Training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,  # Fewer epochs for BERT to avoid overfitting\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=10,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "# )\n",
    "\n",
    "# # Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate\n",
    "# trainer.evaluate()\n",
    "\n",
    "# # Function to predict\n",
    "# def predict_bert(text):\n",
    "#     encoding = tokenizer.encode_plus(\n",
    "#         text,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=512,\n",
    "#         return_token_type_ids=False,\n",
    "#         padding='max_length',\n",
    "#         truncation=True,\n",
    "#         return_attention_mask=True,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**encoding)\n",
    "#         predictions = torch.argmax(outputs.logits, dim=1)\n",
    "#     return label_encoder.inverse_transform(predictions.numpy())[0]\n",
    "\n",
    "# # Test on sample\n",
    "# test_email = \"I am applying for the data analyst position. Attached is my resume.\"\n",
    "# print(f\"BERT Predicted Category: {predict_bert(test_email)}\")\n",
    "\n",
    "# # Test on all categories\n",
    "# unique_categories = df['category'].unique()\n",
    "# print(\"BERT Testing predictions for sample emails from each category:\")\n",
    "# for cat in unique_categories:\n",
    "#     sample_email = df[df['category'] == cat]['email_text'].sample(1).values[0][:200]\n",
    "#     predicted = predict_bert(sample_email)\n",
    "#     print(f\"Category: {cat}\")\n",
    "#     print(f\"Predicted: {predicted}\")\n",
    "#     print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bert_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
